{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T07:31:37.476629Z",
     "start_time": "2019-05-09T07:30:50.602948Z"
    }
   },
   "outputs": [],
   "source": [
    "#全局变量\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "filep='D:\\\\python-document\\\\rerun_review\\\\'\n",
    "pathdid='D:\\\\python-document\\\\rerun_review\\\\did\\\\'\n",
    "import os\n",
    "if not os.path.exists(pathdid):\n",
    "    os.makedirs(pathdid)\n",
    "if not os.path.exists(filep):\n",
    "    os.makedirs(filep)\n",
    "#经常用的函数\n",
    "\n",
    "def trans_time(f):\n",
    "    f1=f.apply(lambda x:parse(x))\n",
    "    f1=f1.apply(lambda x:str(x.year)+'-'+'{:02}'.format(x.month))\n",
    "    return f1\n",
    "def to_time(f):\n",
    "    f1=f.apply(lambda x:parse(x))\n",
    "    return f1\n",
    "def to_str(f):\n",
    "    f1=f.apply(lambda x:str(x.year)+'-'+'{:02}'.format(x.month))\n",
    "    return f1\n",
    "import re\n",
    "def month_differ(x, y):\n",
    "    \"\"\"暂不考虑day, 只根据month和year计算相差月份\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y: 两个datetime.datetime类型的变量\n",
    " \n",
    "    Return\n",
    "    ------\n",
    "    differ: x, y相差的月份\n",
    "    \"\"\"\n",
    "    xyear=np.array([i.year for i in x])\n",
    "    yyear=np.array([i.year for i in y])\n",
    "    xmonth=np.array([i.month for i in x])\n",
    "    ymonth=np.array([i.month for i in y])\n",
    "    month_differ = (xyear - yyear) * 12 + (xmonth - ymonth) * 1\n",
    "    return month_differ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据库导出（评论数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:19.678696Z",
     "start_time": "2019-04-17T16:13:51.672094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 496\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182097 entries, 0 to 182096\n",
      "Data columns (total 15 columns):\n",
      "attraction_id                   182097 non-null object\n",
      "comment_id                      182097 non-null object\n",
      "user_name                       182097 non-null object\n",
      "user_location                   182097 non-null object\n",
      "user_level                      182097 non-null object\n",
      "user_review_counts              182097 non-null object\n",
      "user_attrction_review_counts    182097 non-null object\n",
      "user_votes                      182097 non-null object\n",
      "review_time                     182097 non-null object\n",
      "score                           182097 non-null object\n",
      "comment_topic                   182097 non-null object\n",
      "comment_content                 182097 non-null object\n",
      "comment_thanks                  182097 non-null object\n",
      "visited_time                    182097 non-null object\n",
      "picture_count                   182097 non-null object\n",
      "dtypes: object(15)\n",
      "memory usage: 20.8+ MB\n",
      "06    53398\n",
      "05    30599\n",
      "04    27749\n",
      "1     27187\n",
      "03    25272\n",
      "02    11674\n",
      "01     6218\n",
      "Name: user_level, dtype: int64\n",
      "6    53398\n",
      "1    33405\n",
      "5    30599\n",
      "4    27749\n",
      "3    25272\n",
      "2    11674\n",
      "Name: user_level, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#将sql中的数据导入到dataframe中\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "db_info = {'user': 'root',\n",
    "            'password': '267708',\n",
    "            'host': 'localhost',\n",
    "           'port': 3306,\n",
    "            'database': 'spider'\n",
    "           }\n",
    "\n",
    "engine = create_engine('mysql+pymysql://%(user)s:%(password)s@%(host)s:%(port)d/%(database)s?charset=utf8' % db_info, encoding='utf-8')\n",
    "df = pd.read_sql_table('ta_commentfinal', engine)\n",
    "#df.to_csv(\"d://python-document//tripadviser.csv\")\n",
    "#df.info()\n",
    "df.isnull().sum()\n",
    "#填充空值\n",
    "nacolumn_zero=['user_name','user_votes','comment_thanks','comment_topic','user_review_counts',\n",
    "               'user_attrction_review_counts','picture_count','visited_time']\n",
    "nacolumn_one=['user_level']\n",
    "for i in nacolumn_zero:\n",
    "    df[i]=df[i].fillna(0)\n",
    "for i in nacolumn_one:\n",
    "    df[i]=df[i].fillna(1)\n",
    "df.info()\n",
    "'''\n",
    "for i in df.columns:\n",
    "    df[i]=df[i].fillna(0)\n",
    "df.info()\n",
    "'''\n",
    "#将user_level换成整数\n",
    "print(df.user_level.value_counts())\n",
    "df.user_level=df.user_level.apply(lambda x: int(float(x)))\n",
    "df.user_level[:10]\n",
    "print(df.user_level.value_counts())\n",
    "#将location空格去掉\n",
    "df.user_location=df.user_location.apply(lambda x:x.strip())#只能运行一遍\n",
    "df.head()\n",
    "print(sum(df.duplicated()))#是否有重复值\n",
    "df['review_time']=df['review_time'].apply(lambda x:x.strip())#去除不必要的空格\n",
    "#处理visited_time\n",
    "import re\n",
    "df['visited_time']=df['visited_time'].apply(lambda x:str(x).strip())#去除不必要的空格\n",
    "df['visited_time']=df['visited_time'].apply(lambda x:re.search('Visited (.*)',x)[1] if x!='0' else '0')\n",
    "#df['visited_time'][:4]   \n",
    "df.to_csv(\"%s1.1com_origin.csv\"%filep,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:37.512716Z",
     "start_time": "2019-04-17T16:14:19.681696Z"
    }
   },
   "outputs": [],
   "source": [
    "#处理时间，review_time不变\n",
    "df=pd.read_csv(\"%s1.1com_origin.csv\"%filep)\n",
    "df['review_time']=trans_time(df['review_time'])\n",
    "#df['review_time_origin']=df['review_time']\n",
    "#df['visited_time'][df.visited_time=='0']=df['review_time'][df.visited_time=='0']#将顺序反过来就没有变\n",
    "#df['visited_time']=trans_time(df['visited_time'])\n",
    "#df['review_time']=df['visited_time']\n",
    "\n",
    "#处理review_time\n",
    "#df['visit_review']=month_differ(to_time(df['review_time_origin']),to_time(df['visited_time']))\n",
    "#print((df['visit_review']>=0).sum())#171631rows\n",
    "#df['review_time'][df['visit_review']>=0]=df['visited_time'][df['visit_review']>=0]\n",
    "#print((df['review_time']<df['visited_time']).sum())#10466这是时间出错的评论数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#处理时间,根据visit_time填充\n",
    "df=pd.read_csv(\"%s1.1com_origin.csv\"%filep)\n",
    "df['review_time']=trans_time(df['review_time'])\n",
    "df['review_time_origin']=df['review_time']\n",
    "df['visited_time'][df.visited_time=='0']=df['review_time'][df.visited_time=='0']#将顺序反过来就没有变\n",
    "df['visited_time']=trans_time(df['visited_time'])\n",
    "#df['review_time']=df['visited_time']\n",
    "\n",
    "#处理review_time\n",
    "df['visit_review']=month_differ(to_time(df['review_time_origin']),to_time(df['visited_time']))\n",
    "print((df['visit_review']>=0).sum())#171631rows\n",
    "df['review_time'][df['visit_review']>=0]=df['visited_time'][df['visit_review']>=0]\n",
    "print((df['review_time']<df['visited_time']).sum())#10466这是时间出错的评论数\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:39.282817Z",
     "start_time": "2019-04-17T16:14:37.514716Z"
    }
   },
   "outputs": [],
   "source": [
    "df['comment_content_count']=df['comment_content'].apply(lambda x:len([i for i in x.strip().split(' ')]))\n",
    "df['comment_counts']=1\n",
    "df_groupby=df.groupby(['attraction_id',\"review_time\"])['user_level', 'user_review_counts', 'user_attrction_review_counts',\n",
    "'user_votes', 'score','comment_thanks','comment_content_count','picture_count'].mean().reset_index()\n",
    "comment_count=df.groupby(['attraction_id',\"review_time\"])['comment_counts'].sum().reset_index()\n",
    "#comment_count=data.groupby(['attraction_id',\"review_time\"]).agg('comment_content_count',count)\n",
    "df_groupby=pd.merge(df_groupby,comment_count,on=['attraction_id',\"review_time\"],how='left')\n",
    "#取小数\n",
    "df_groupby['attraction_id']=df_groupby['attraction_id'].apply(lambda x:str(x))\n",
    "for i in df_groupby.columns[2:]:\n",
    "    df_groupby[i]= df_groupby[i].apply(lambda x:round(x,2))\n",
    "df_groupby.to_csv(\"%s1.1com_bymonth.csv\"%filep,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:39.389824Z",
     "start_time": "2019-04-17T16:14:39.288818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groupby.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合景点数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:41.613951Z",
     "start_time": "2019-04-17T16:14:39.392824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20093 entries, 0 to 20350\n",
      "Data columns (total 25 columns):\n",
      "attraction_id                   20093 non-null int64\n",
      "review_time                     20093 non-null object\n",
      "user_level                      20093 non-null float64\n",
      "user_review_counts              20093 non-null float64\n",
      "user_attrction_review_counts    20093 non-null float64\n",
      "user_votes                      20093 non-null float64\n",
      "score                           20093 non-null float64\n",
      "comment_thanks                  20093 non-null float64\n",
      "comment_content_count           20093 non-null float64\n",
      "picture_count                   20093 non-null float64\n",
      "comment_counts                  20093 non-null int64\n",
      "id                              20093 non-null float64\n",
      "name                            20093 non-null object\n",
      "walk score                      20093 non-null float64\n",
      "transit score                   20093 non-null float64\n",
      "bike score                      20093 non-null float64\n",
      "types                           20093 non-null object\n",
      "rating                          20080 non-null float64\n",
      "reviews                         14085 non-null float64\n",
      "raking                          20093 non-null float64\n",
      "group                           20093 non-null float64\n",
      "address                         20093 non-null object\n",
      "near                            14963 non-null object\n",
      "latitude                        20093 non-null float64\n",
      "longitude                       20093 non-null float64\n",
      "dtypes: float64(18), int64(2), object(5)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#景点主页数据\n",
    "attraction=pd.read_excel(u'F:\\\\研究生毕设数据\\\\divvybike data\\\\data.xlsx',sheet_name='all')\n",
    "attraction.dropna(subset=['latitude'],inplace=True)#去掉坐标为空的景点\n",
    "attraction.to_csv(\"%s1.2attraction.csv\"%filep,index=False)\n",
    "\n",
    "#将评论数据与景点的位置联系起来\n",
    "attaction=pd.read_csv(\"%s1.2attraction.csv\"%filep)\n",
    "attaction.shape\n",
    "tripadviser=pd.read_csv(\"%s1.1com_bymonth.csv\"%filep)\n",
    "trip_attraction=pd.merge(tripadviser,attaction,left_on='attraction_id',right_on='id',how='left')\n",
    "#trip_attraction.dropna(subset=['latitude'],inplace=True)#去掉坐标为空的景点\n",
    "#去除坐标值为空的数据\n",
    "trip_attraction.dropna(subset=['latitude'],inplace=True)#去掉坐标为空的景点\n",
    "trip_attraction.info()\n",
    "trip_attraction.to_csv(\"%s1.2comment_attraction.csv\"%filep,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合站点数据（按距离）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 站点数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:14:41.861965Z",
     "start_time": "2019-04-17T16:14:41.614951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-06    86\n",
       "2013-07    85\n",
       "2016-05    80\n",
       "2015-02    79\n",
       "2013-09    79\n",
       "2013-08    67\n",
       "2015-01    61\n",
       "2016-06    23\n",
       "2013-10    13\n",
       "2016-07     2\n",
       "2013-12     2\n",
       "2017-04     1\n",
       "2014-01     1\n",
       "2017-12     1\n",
       "2014-03     1\n",
       "2017-07     1\n",
       "2014-04     1\n",
       "2017-06     1\n",
       "2017-08     1\n",
       "Name: online_date1, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "station=pd.read_csv(u'F:\\\\研究生毕设数据\\\\divvybike data\\\\Divvy_Trips_2017_Q3Q4\\\\Divvy_Stations_2017_Q3Q4.csv',\n",
    "                    encoding='utf-8',engine='python')\n",
    "#station.drop(station.columns[-1],axis=1,inplace=True)#去掉最后的空列\n",
    "station['online_date1']=trans_time(station['online_date'])\n",
    "station.to_csv(\"%s1.3.1station.csv\"%filep,index=False)\n",
    "station['online_date1'].value_counts()#主要集中于2013,2015,2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最短距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:44:13.615303Z",
     "start_time": "2019-04-17T16:14:41.872966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20093\n",
      "(20093, 27)\n",
      "585\n",
      "729\n"
     ]
    }
   ],
   "source": [
    "#然后计算与station在对应时间的最近位置\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic#可以简便计算位置的包，包含很多与地理数据处理有关的方法\n",
    "trip_attraction=pd.read_csv(\"%s1.2comment_attraction.csv\"%filep)\n",
    "station=pd.read_csv(\"%s1.3.1station.csv\"%filep)\n",
    "\n",
    "#最短距离及对应站点\n",
    "final=[]\n",
    "for i in trip_attraction.index: \n",
    "#    print(trip_attraction.loc[i].values[2])\n",
    "    stationslice=station[station['online_date1']<=trip_attraction['review_time'][i]]\n",
    "    distance={}\n",
    "    a=trip_attraction.loc[i].values[-2]\n",
    "    b=trip_attraction.loc[i].values[-1]\n",
    "    for x,y,z in zip(stationslice['latitude'].values,stationslice['longitude'].values,stationslice['id'].values):\n",
    "        dis=geodesic((a,b), (x,y)).m\n",
    "        distance[z]=dis\n",
    "    if len(distance)==0:\n",
    "        final.append(('null','null'))\n",
    "    else:\n",
    "        final.append(min(distance.items(), key=lambda x: x[1]))\n",
    "print(len(final))\n",
    "#然后将最短距离字典进行整合\n",
    "final1=pd.DataFrame(final,columns=['recent_station','shortest_dis'])\n",
    "trip_attraction1=pd.concat([trip_attraction,final1],axis=1)\n",
    "trip_attraction1['shortest_dis']=trip_attraction1['shortest_dis'].apply(lambda x:0 if x=='null' else x)\n",
    "trip_attraction1['recent_station']=trip_attraction1['recent_station'].apply(lambda x:0 if x=='null' else x)\n",
    "#trip_attraction1['shortest_dis']=trip_attraction1['shortest_dis'].fillna(100000).apply(lambda x:round(float(x),0))\n",
    "trip_attraction1.to_csv(\"%s1.3.2shortest_dis.csv\"%filep,index=0)\n",
    "print(trip_attraction1.shape)#(20391, 27)\n",
    "print(sum(trip_attraction1['shortest_dis'].values>=800))#585   600\n",
    "print(sum(trip_attraction1['shortest_dis'].values>=600))#729  749"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 距离中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T17:21:14.768346Z",
     "start_time": "2019-04-17T16:44:13.621304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15991\n"
     ]
    }
   ],
   "source": [
    "#做200m，300m等\n",
    "from geopy.distance import geodesic#可以简便计算位置的包，包含很多与地理数据处理有关的方法\n",
    "trip_attraction=pd.read_csv(\"%s1.3.2shortest_dis.csv\"%filep)\n",
    "station=pd.read_csv(\"%s1.3.1station.csv\"%filep)\n",
    "\n",
    "#计算中间结果\n",
    "final=[]\n",
    "for i in trip_attraction.index: \n",
    "    stationslice=station[station['online_date1']<=trip_attraction.loc[i]['review_time']]\n",
    "    a=trip_attraction.loc[i]['latitude']\n",
    "    b=trip_attraction.loc[i]['longitude']\n",
    "    if not stationslice.empty:\n",
    "        jieguozj=[]\n",
    "        for x,y,z,d in zip(stationslice['latitude'].values,stationslice['longitude'].values,stationslice['id'].values,\n",
    "                   stationslice['online_date1'] ):\n",
    "            dis=geodesic((a,b), (x,y)).m\n",
    "            jieguozj.append([trip_attraction['attraction_id'][i],trip_attraction['review_time'][i],z,d,dis])\n",
    "        final.append(jieguozj)\n",
    "print(len(final))\n",
    "#保存中间结果并分析，将其整理到原来的表中\n",
    "#保存中间结果，做好备份\n",
    "for item in final:\n",
    "    with open(\"%s1.3.3distance_of_station_attraction.txt\"%filep,'a') as f:\n",
    "        f.write(str(item)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 具体距离（200m等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:50:58.243999Z",
     "start_time": "2019-04-26T13:48:55.000950Z"
    }
   },
   "outputs": [],
   "source": [
    "#读取结果并分析\n",
    "import pandas as pd\n",
    "def read_mjieguo(f):\n",
    "    with open(f,'r') as f:\n",
    "        for i in f:\n",
    "            yield i\n",
    "f=\"%s1.3.3distance_of_station_attraction.txt\"%filep\n",
    "def calcD(d=0):\n",
    "    huizong=[]\n",
    "    for i in read_mjieguo(f):\n",
    "        ad=pd.DataFrame(eval(i),columns=['attraction_id','review_time','station_id','station_onlinetime','distance'])\n",
    "        ad['distance']=ad['distance'].apply(lambda x:int(round(float(x),0)))\n",
    "        ads=ad[ad.distance<=d]\n",
    "        if not ads.empty:\n",
    "            alist=[list(ads.attraction_id)[0],list(ads.review_time)[0],list(ads['station_id']),\n",
    "                   list(ads['station_onlinetime']),list(ads['distance'])]#不一定能被赋值\n",
    "            #赋值之后变成了局部变量，搞不懂\n",
    "            huizong.append(alist)\n",
    "    huizong1=pd.DataFrame(huizong,\n",
    "                          columns=['attraction_id','review_time','station_id','station_onlinetime','distance']) \n",
    "    huizong1.to_csv(\"%s1.3.4_\"%filep+str(d)+\"m.csv\",index=False)\n",
    "#calcD(d=200)\n",
    "#calcD(d=300)\n",
    "calcD(d=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:50:59.981099Z",
     "start_time": "2019-04-26T13:50:58.245999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attraction_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>user_level</th>\n",
       "      <th>user_review_counts</th>\n",
       "      <th>user_attrction_review_counts</th>\n",
       "      <th>user_votes</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_thanks</th>\n",
       "      <th>comment_content_count</th>\n",
       "      <th>picture_count</th>\n",
       "      <th>...</th>\n",
       "      <th>group</th>\n",
       "      <th>address</th>\n",
       "      <th>near</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>recent_station</th>\n",
       "      <th>shortest_dis</th>\n",
       "      <th>station_time_100</th>\n",
       "      <th>has_station_100</th>\n",
       "      <th>station_count_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103238</td>\n",
       "      <td>2002-02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-09</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103238</td>\n",
       "      <td>2004-12</td>\n",
       "      <td>4.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>272.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>141.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103238</td>\n",
       "      <td>2005-09</td>\n",
       "      <td>6.00</td>\n",
       "      <td>185.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103238</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>5.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>387.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103238</td>\n",
       "      <td>2006-05</td>\n",
       "      <td>4.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>103238</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>6.00</td>\n",
       "      <td>378.50</td>\n",
       "      <td>104.00</td>\n",
       "      <td>373.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>103238</td>\n",
       "      <td>2006-08</td>\n",
       "      <td>6.00</td>\n",
       "      <td>171.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>123.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103238</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>262.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>251.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>5.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-03</td>\n",
       "      <td>3.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>93.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-04</td>\n",
       "      <td>5.00</td>\n",
       "      <td>185.00</td>\n",
       "      <td>74.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>74.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>308.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>91.00</td>\n",
       "      <td>36.67</td>\n",
       "      <td>85.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>132.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-09</td>\n",
       "      <td>6.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>103238</td>\n",
       "      <td>2007-11</td>\n",
       "      <td>6.00</td>\n",
       "      <td>141.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>371.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-01</td>\n",
       "      <td>6.00</td>\n",
       "      <td>496.00</td>\n",
       "      <td>436.00</td>\n",
       "      <td>471.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-04</td>\n",
       "      <td>6.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-05</td>\n",
       "      <td>6.00</td>\n",
       "      <td>243.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>277.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-08</td>\n",
       "      <td>6.00</td>\n",
       "      <td>170.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>103238</td>\n",
       "      <td>2008-11</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103238</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>37.50</td>\n",
       "      <td>13.50</td>\n",
       "      <td>33.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103238</td>\n",
       "      <td>2009-02</td>\n",
       "      <td>6.00</td>\n",
       "      <td>328.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>461.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>103238</td>\n",
       "      <td>2009-03</td>\n",
       "      <td>4.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>233 S. Wacker Drive,Entrance on Jackson Blvd,C...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.878700</td>\n",
       "      <td>-87.635980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20063</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>3.40</td>\n",
       "      <td>99.20</td>\n",
       "      <td>28.20</td>\n",
       "      <td>20.70</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>49.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20064</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>4.86</td>\n",
       "      <td>190.86</td>\n",
       "      <td>57.71</td>\n",
       "      <td>96.43</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20065</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>4.38</td>\n",
       "      <td>80.62</td>\n",
       "      <td>22.50</td>\n",
       "      <td>28.50</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>95.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20066</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>169.40</td>\n",
       "      <td>67.20</td>\n",
       "      <td>45.20</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>68.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>33.00</td>\n",
       "      <td>12.20</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>67.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20068</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>4.00</td>\n",
       "      <td>35.33</td>\n",
       "      <td>4.67</td>\n",
       "      <td>7.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>4.75</td>\n",
       "      <td>49.75</td>\n",
       "      <td>15.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>4.75</td>\n",
       "      <td>77.00</td>\n",
       "      <td>20.25</td>\n",
       "      <td>29.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>3.53</td>\n",
       "      <td>46.87</td>\n",
       "      <td>11.07</td>\n",
       "      <td>12.87</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.93</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>4.09</td>\n",
       "      <td>158.55</td>\n",
       "      <td>32.91</td>\n",
       "      <td>45.00</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20073</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>3.43</td>\n",
       "      <td>138.00</td>\n",
       "      <td>43.57</td>\n",
       "      <td>68.43</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>62.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20074</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20075</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-07</td>\n",
       "      <td>4.00</td>\n",
       "      <td>82.25</td>\n",
       "      <td>18.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20076</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>4.60</td>\n",
       "      <td>86.40</td>\n",
       "      <td>31.20</td>\n",
       "      <td>27.40</td>\n",
       "      <td>4.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>63.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20077</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>4.25</td>\n",
       "      <td>54.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.50</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20078</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>4.33</td>\n",
       "      <td>91.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>30.67</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>82.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20079</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.40</td>\n",
       "      <td>41.60</td>\n",
       "      <td>64.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>58.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20080</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>4.50</td>\n",
       "      <td>94.00</td>\n",
       "      <td>24.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20081</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>4.50</td>\n",
       "      <td>83.25</td>\n",
       "      <td>24.00</td>\n",
       "      <td>43.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20082</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>3.75</td>\n",
       "      <td>64.50</td>\n",
       "      <td>14.50</td>\n",
       "      <td>27.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>49.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20083</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>3.00</td>\n",
       "      <td>28.57</td>\n",
       "      <td>5.57</td>\n",
       "      <td>9.29</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.29</td>\n",
       "      <td>54.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20084</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>4.00</td>\n",
       "      <td>168.60</td>\n",
       "      <td>67.40</td>\n",
       "      <td>51.60</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>61.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20085</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-05</td>\n",
       "      <td>5.50</td>\n",
       "      <td>140.50</td>\n",
       "      <td>69.00</td>\n",
       "      <td>97.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20086</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>5.00</td>\n",
       "      <td>123.57</td>\n",
       "      <td>40.57</td>\n",
       "      <td>31.29</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20087</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>6.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20088</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>5.50</td>\n",
       "      <td>107.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20089</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-09</td>\n",
       "      <td>4.50</td>\n",
       "      <td>57.25</td>\n",
       "      <td>6.75</td>\n",
       "      <td>17.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090</th>\n",
       "      <td>14931740</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>26 W Hubbard St,Chicago, IL 60654-4606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.890278</td>\n",
       "      <td>-87.629074</td>\n",
       "      <td>47</td>\n",
       "      <td>163.357927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20091</th>\n",
       "      <td>14933686</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>4.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>291.0</td>\n",
       "      <td>410 S Michigan Ave,2nd Floor,Chicago, IL 60605...</td>\n",
       "      <td>Downtown / The Loop</td>\n",
       "      <td>41.875990</td>\n",
       "      <td>-87.624870</td>\n",
       "      <td>45</td>\n",
       "      <td>46.347610</td>\n",
       "      <td>2013-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20092</th>\n",
       "      <td>14956061</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>6.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>194.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2248 W Washington Blvd,Chicago, IL 60612-2236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.883290</td>\n",
       "      <td>-87.683350</td>\n",
       "      <td>381</td>\n",
       "      <td>451.567399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20093 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attraction_id review_time  user_level  user_review_counts  \\\n",
       "0             103238     2002-02        1.00                0.00   \n",
       "1             103238     2004-01        1.00                1.00   \n",
       "2             103238     2004-03        1.00                1.00   \n",
       "3             103238     2004-04        1.00                1.00   \n",
       "4             103238     2004-09        2.00                9.00   \n",
       "5             103238     2004-10        1.00                1.00   \n",
       "6             103238     2004-12        4.00               24.00   \n",
       "7             103238     2005-09        6.00              185.00   \n",
       "8             103238     2006-01        5.00               52.00   \n",
       "9             103238     2006-05        4.00               31.00   \n",
       "10            103238     2006-07        6.00              378.50   \n",
       "11            103238     2006-08        6.00              171.00   \n",
       "12            103238     2006-12        6.00              262.00   \n",
       "13            103238     2007-01        5.00               44.00   \n",
       "14            103238     2007-03        3.00               12.00   \n",
       "15            103238     2007-04        5.00              185.00   \n",
       "16            103238     2007-06        1.00                4.00   \n",
       "17            103238     2007-07        4.33               91.00   \n",
       "18            103238     2007-08        1.00                1.00   \n",
       "19            103238     2007-09        6.00              108.00   \n",
       "20            103238     2007-11        6.00              141.00   \n",
       "21            103238     2008-01        6.00              496.00   \n",
       "22            103238     2008-04        6.00               76.00   \n",
       "23            103238     2008-05        6.00              243.00   \n",
       "24            103238     2008-08        6.00              170.00   \n",
       "25            103238     2008-09        1.00                1.00   \n",
       "26            103238     2008-11        2.00               11.50   \n",
       "27            103238     2009-01        3.00               37.50   \n",
       "28            103238     2009-02        6.00              328.00   \n",
       "29            103238     2009-03        4.00               36.00   \n",
       "...              ...         ...         ...                 ...   \n",
       "20063       14931740     2016-07        3.40               99.20   \n",
       "20064       14931740     2016-08        4.86              190.86   \n",
       "20065       14931740     2016-09        4.38               80.62   \n",
       "20066       14931740     2016-10        3.40              169.40   \n",
       "20067       14931740     2016-11        3.60               33.00   \n",
       "20068       14931740     2016-12        4.00               35.33   \n",
       "20069       14931740     2017-01        4.75               49.75   \n",
       "20070       14931740     2017-02        4.75               77.00   \n",
       "20071       14931740     2017-03        3.53               46.87   \n",
       "20072       14931740     2017-04        4.09              158.55   \n",
       "20073       14931740     2017-05        3.43              138.00   \n",
       "20074       14931740     2017-06        3.00               15.00   \n",
       "20075       14931740     2017-07        4.00               82.25   \n",
       "20076       14931740     2017-08        4.60               86.40   \n",
       "20077       14931740     2017-09        4.25               54.00   \n",
       "20078       14931740     2017-10        4.33               91.00   \n",
       "20079       14931740     2017-11        5.00              190.40   \n",
       "20080       14931740     2017-12        4.50               94.00   \n",
       "20081       14931740     2018-01        4.50               83.25   \n",
       "20082       14931740     2018-02        3.75               64.50   \n",
       "20083       14931740     2018-03        3.00               28.57   \n",
       "20084       14931740     2018-04        4.00              168.60   \n",
       "20085       14931740     2018-05        5.50              140.50   \n",
       "20086       14931740     2018-06        5.00              123.57   \n",
       "20087       14931740     2018-07        6.00              121.00   \n",
       "20088       14931740     2018-08        5.50              107.00   \n",
       "20089       14931740     2018-09        4.50               57.25   \n",
       "20090       14931740     2018-10        1.00                2.00   \n",
       "20091       14933686     2018-07        4.00               25.00   \n",
       "20092       14956061     2018-07        6.00              384.00   \n",
       "\n",
       "       user_attrction_review_counts  user_votes  score  comment_thanks  \\\n",
       "0                              0.00        0.00   4.00           18.00   \n",
       "1                              0.00        8.00   5.00            8.00   \n",
       "2                              0.00        5.00   3.00            5.00   \n",
       "3                              0.00        9.00   5.00            9.00   \n",
       "4                              5.00       37.00   5.00           14.00   \n",
       "5                              0.00       17.00   5.00           17.00   \n",
       "6                              9.50      272.50   3.50           22.50   \n",
       "7                             35.00      300.00   4.00           12.00   \n",
       "8                             10.00       71.00   1.00           35.00   \n",
       "9                              8.00      103.00   4.00           10.00   \n",
       "10                           104.00      373.00   2.00            8.50   \n",
       "11                            77.00      123.00   4.00            2.00   \n",
       "12                            68.00       87.00   1.00            3.00   \n",
       "13                            11.00      108.00   3.00            2.00   \n",
       "14                             3.00       33.00   2.00            2.00   \n",
       "15                            74.50      189.50   4.00            0.50   \n",
       "16                             0.00       13.00   3.00            6.00   \n",
       "17                            36.67       85.67   3.67            4.33   \n",
       "18                             0.00        0.00   5.00            0.00   \n",
       "19                            20.00       75.00   3.00            1.00   \n",
       "20                            38.00      225.00   4.00            8.00   \n",
       "21                           436.00      471.00   5.00            0.00   \n",
       "22                            28.00       80.00   5.00            0.00   \n",
       "23                           114.00      277.00   5.00            0.00   \n",
       "24                            41.00      200.00   4.00            2.00   \n",
       "25                             0.00        1.00   5.00            1.00   \n",
       "26                             4.00        8.00   4.50            0.50   \n",
       "27                            13.50       33.50   5.00            0.00   \n",
       "28                           203.00      461.00   3.00            2.00   \n",
       "29                            11.00       18.00   4.00            0.00   \n",
       "...                             ...         ...    ...             ...   \n",
       "20063                         28.20       20.70   4.00            0.20   \n",
       "20064                         57.71       96.43   4.14            0.29   \n",
       "20065                         22.50       28.50   4.12            1.00   \n",
       "20066                         67.20       45.20   4.40            0.20   \n",
       "20067                         12.20       15.00   4.40            0.20   \n",
       "20068                          4.67        7.33   5.00            0.00   \n",
       "20069                         15.75        9.25   4.75            0.00   \n",
       "20070                         20.25       29.25   4.25            0.00   \n",
       "20071                         11.07       12.87   3.80            0.00   \n",
       "20072                         32.91       45.00   2.91            0.00   \n",
       "20073                         43.57       68.43   3.00            0.14   \n",
       "20074                          2.00        9.00   3.50            0.00   \n",
       "20075                         18.00       29.00   4.75            0.25   \n",
       "20076                         31.20       27.40   4.40            1.00   \n",
       "20077                         15.00       17.50   4.25            0.25   \n",
       "20078                         27.50       30.67   4.50            0.00   \n",
       "20079                         41.60       64.80   4.60            0.20   \n",
       "20080                         24.50       22.50   5.00            0.00   \n",
       "20081                         24.00       43.50   5.00            0.00   \n",
       "20082                         14.50       27.00   4.50            0.25   \n",
       "20083                          5.57        9.29   3.57            0.29   \n",
       "20084                         67.40       51.60   4.60            0.20   \n",
       "20085                         69.00       97.50   4.00            0.00   \n",
       "20086                         40.57       31.29   4.43            0.00   \n",
       "20087                         31.00       79.00   4.50            0.00   \n",
       "20088                         38.00       16.00   3.00            0.00   \n",
       "20089                          6.75       17.25   4.25            0.00   \n",
       "20090                          0.00        2.00   5.00            0.00   \n",
       "20091                          8.00        5.00   4.00            0.00   \n",
       "20092                        115.00       81.00   4.00            0.00   \n",
       "\n",
       "       comment_content_count  picture_count        ...          group  \\\n",
       "0                      80.00           0.00        ...          705.0   \n",
       "1                      21.00           0.00        ...          705.0   \n",
       "2                      47.00           0.00        ...          705.0   \n",
       "3                      67.00           0.00        ...          705.0   \n",
       "4                      40.00           0.00        ...          705.0   \n",
       "5                      71.00           0.00        ...          705.0   \n",
       "6                     141.00           0.00        ...          705.0   \n",
       "7                     124.00           0.00        ...          705.0   \n",
       "8                     387.00           0.00        ...          705.0   \n",
       "9                      84.00           0.00        ...          705.0   \n",
       "10                     80.00           0.00        ...          705.0   \n",
       "11                     94.00           0.00        ...          705.0   \n",
       "12                    251.00           0.00        ...          705.0   \n",
       "13                     71.00           0.00        ...          705.0   \n",
       "14                     93.00           0.00        ...          705.0   \n",
       "15                     74.00           0.00        ...          705.0   \n",
       "16                    308.00           0.00        ...          705.0   \n",
       "17                    132.33           1.00        ...          705.0   \n",
       "18                     81.00           0.00        ...          705.0   \n",
       "19                     59.00           0.00        ...          705.0   \n",
       "20                    371.00           5.00        ...          705.0   \n",
       "21                     49.00           0.00        ...          705.0   \n",
       "22                     66.00           0.00        ...          705.0   \n",
       "23                     62.00           0.00        ...          705.0   \n",
       "24                    232.00           0.00        ...          705.0   \n",
       "25                     82.00           0.00        ...          705.0   \n",
       "26                     48.00           1.50        ...          705.0   \n",
       "27                     59.00           0.00        ...          705.0   \n",
       "28                    255.00           3.00        ...          705.0   \n",
       "29                     94.00           0.00        ...          705.0   \n",
       "...                      ...            ...        ...            ...   \n",
       "20063                  49.80           0.30        ...          577.0   \n",
       "20064                  72.29           0.00        ...          577.0   \n",
       "20065                  95.75           0.00        ...          577.0   \n",
       "20066                  68.60           0.00        ...          577.0   \n",
       "20067                  67.00           0.00        ...          577.0   \n",
       "20068                  25.33           0.00        ...          577.0   \n",
       "20069                 158.00           0.50        ...          577.0   \n",
       "20070                  55.25           0.00        ...          577.0   \n",
       "20071                  54.93           0.27        ...          577.0   \n",
       "20072                  65.45           0.00        ...          577.0   \n",
       "20073                  62.57           0.00        ...          577.0   \n",
       "20074                  44.00           0.00        ...          577.0   \n",
       "20075                  75.75           0.25        ...          577.0   \n",
       "20076                  63.80           0.00        ...          577.0   \n",
       "20077                  50.75           0.25        ...          577.0   \n",
       "20078                  82.67           0.00        ...          577.0   \n",
       "20079                  58.40           0.20        ...          577.0   \n",
       "20080                  59.50           0.00        ...          577.0   \n",
       "20081                  52.50           0.00        ...          577.0   \n",
       "20082                  49.75           0.00        ...          577.0   \n",
       "20083                  54.86           0.00        ...          577.0   \n",
       "20084                  61.40           0.00        ...          577.0   \n",
       "20085                  51.50           0.00        ...          577.0   \n",
       "20086                  66.86           0.86        ...          577.0   \n",
       "20087                 121.50           1.00        ...          577.0   \n",
       "20088                  61.50           0.50        ...          577.0   \n",
       "20089                  90.50           0.00        ...          577.0   \n",
       "20090                  46.00           0.00        ...          577.0   \n",
       "20091                 135.00           0.00        ...          291.0   \n",
       "20092                 194.00           0.00        ...          705.0   \n",
       "\n",
       "                                                 address                 near  \\\n",
       "0      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "1      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "2      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "3      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "4      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "5      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "6      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "7      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "8      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "9      233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "10     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "11     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "12     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "13     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "14     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "15     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "16     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "17     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "18     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "19     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "20     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "21     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "22     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "23     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "24     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "25     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "26     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "27     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "28     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "29     233 S. Wacker Drive,Entrance on Jackson Blvd,C...  Downtown / The Loop   \n",
       "...                                                  ...                  ...   \n",
       "20063             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20064             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20065             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20066             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20067             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20068             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20069             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20070             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20071             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20072             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20073             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20074             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20075             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20076             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20077             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20078             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20079             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20080             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20081             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20082             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20083             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20084             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20085             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20086             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20087             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20088             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20089             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20090             26 W Hubbard St,Chicago, IL 60654-4606                  NaN   \n",
       "20091  410 S Michigan Ave,2nd Floor,Chicago, IL 60605...  Downtown / The Loop   \n",
       "20092      2248 W Washington Blvd,Chicago, IL 60612-2236                  NaN   \n",
       "\n",
       "        latitude  longitude  recent_station shortest_dis  station_time_100  \\\n",
       "0      41.878700 -87.635980               0     0.000000                 0   \n",
       "1      41.878700 -87.635980               0     0.000000                 0   \n",
       "2      41.878700 -87.635980               0     0.000000                 0   \n",
       "3      41.878700 -87.635980               0     0.000000                 0   \n",
       "4      41.878700 -87.635980               0     0.000000                 0   \n",
       "5      41.878700 -87.635980               0     0.000000                 0   \n",
       "6      41.878700 -87.635980               0     0.000000                 0   \n",
       "7      41.878700 -87.635980               0     0.000000                 0   \n",
       "8      41.878700 -87.635980               0     0.000000                 0   \n",
       "9      41.878700 -87.635980               0     0.000000                 0   \n",
       "10     41.878700 -87.635980               0     0.000000                 0   \n",
       "11     41.878700 -87.635980               0     0.000000                 0   \n",
       "12     41.878700 -87.635980               0     0.000000                 0   \n",
       "13     41.878700 -87.635980               0     0.000000                 0   \n",
       "14     41.878700 -87.635980               0     0.000000                 0   \n",
       "15     41.878700 -87.635980               0     0.000000                 0   \n",
       "16     41.878700 -87.635980               0     0.000000                 0   \n",
       "17     41.878700 -87.635980               0     0.000000                 0   \n",
       "18     41.878700 -87.635980               0     0.000000                 0   \n",
       "19     41.878700 -87.635980               0     0.000000                 0   \n",
       "20     41.878700 -87.635980               0     0.000000                 0   \n",
       "21     41.878700 -87.635980               0     0.000000                 0   \n",
       "22     41.878700 -87.635980               0     0.000000                 0   \n",
       "23     41.878700 -87.635980               0     0.000000                 0   \n",
       "24     41.878700 -87.635980               0     0.000000                 0   \n",
       "25     41.878700 -87.635980               0     0.000000                 0   \n",
       "26     41.878700 -87.635980               0     0.000000                 0   \n",
       "27     41.878700 -87.635980               0     0.000000                 0   \n",
       "28     41.878700 -87.635980               0     0.000000                 0   \n",
       "29     41.878700 -87.635980               0     0.000000                 0   \n",
       "...          ...        ...             ...          ...               ...   \n",
       "20063  41.890278 -87.629074              47   163.357927                 0   \n",
       "20064  41.890278 -87.629074              47   163.357927                 0   \n",
       "20065  41.890278 -87.629074              47   163.357927                 0   \n",
       "20066  41.890278 -87.629074              47   163.357927                 0   \n",
       "20067  41.890278 -87.629074              47   163.357927                 0   \n",
       "20068  41.890278 -87.629074              47   163.357927                 0   \n",
       "20069  41.890278 -87.629074              47   163.357927                 0   \n",
       "20070  41.890278 -87.629074              47   163.357927                 0   \n",
       "20071  41.890278 -87.629074              47   163.357927                 0   \n",
       "20072  41.890278 -87.629074              47   163.357927                 0   \n",
       "20073  41.890278 -87.629074              47   163.357927                 0   \n",
       "20074  41.890278 -87.629074              47   163.357927                 0   \n",
       "20075  41.890278 -87.629074              47   163.357927                 0   \n",
       "20076  41.890278 -87.629074              47   163.357927                 0   \n",
       "20077  41.890278 -87.629074              47   163.357927                 0   \n",
       "20078  41.890278 -87.629074              47   163.357927                 0   \n",
       "20079  41.890278 -87.629074              47   163.357927                 0   \n",
       "20080  41.890278 -87.629074              47   163.357927                 0   \n",
       "20081  41.890278 -87.629074              47   163.357927                 0   \n",
       "20082  41.890278 -87.629074              47   163.357927                 0   \n",
       "20083  41.890278 -87.629074              47   163.357927                 0   \n",
       "20084  41.890278 -87.629074              47   163.357927                 0   \n",
       "20085  41.890278 -87.629074              47   163.357927                 0   \n",
       "20086  41.890278 -87.629074              47   163.357927                 0   \n",
       "20087  41.890278 -87.629074              47   163.357927                 0   \n",
       "20088  41.890278 -87.629074              47   163.357927                 0   \n",
       "20089  41.890278 -87.629074              47   163.357927                 0   \n",
       "20090  41.890278 -87.629074              47   163.357927                 0   \n",
       "20091  41.875990 -87.624870              45    46.347610           2013-06   \n",
       "20092  41.883290 -87.683350             381   451.567399                 0   \n",
       "\n",
       "       has_station_100  station_count_100  \n",
       "0                  0.0                0.0  \n",
       "1                  0.0                0.0  \n",
       "2                  0.0                0.0  \n",
       "3                  0.0                0.0  \n",
       "4                  0.0                0.0  \n",
       "5                  0.0                0.0  \n",
       "6                  0.0                0.0  \n",
       "7                  0.0                0.0  \n",
       "8                  0.0                0.0  \n",
       "9                  0.0                0.0  \n",
       "10                 0.0                0.0  \n",
       "11                 0.0                0.0  \n",
       "12                 0.0                0.0  \n",
       "13                 0.0                0.0  \n",
       "14                 0.0                0.0  \n",
       "15                 0.0                0.0  \n",
       "16                 0.0                0.0  \n",
       "17                 0.0                0.0  \n",
       "18                 0.0                0.0  \n",
       "19                 0.0                0.0  \n",
       "20                 0.0                0.0  \n",
       "21                 0.0                0.0  \n",
       "22                 0.0                0.0  \n",
       "23                 0.0                0.0  \n",
       "24                 0.0                0.0  \n",
       "25                 0.0                0.0  \n",
       "26                 0.0                0.0  \n",
       "27                 0.0                0.0  \n",
       "28                 0.0                0.0  \n",
       "29                 0.0                0.0  \n",
       "...                ...                ...  \n",
       "20063              0.0                0.0  \n",
       "20064              0.0                0.0  \n",
       "20065              0.0                0.0  \n",
       "20066              0.0                0.0  \n",
       "20067              0.0                0.0  \n",
       "20068              0.0                0.0  \n",
       "20069              0.0                0.0  \n",
       "20070              0.0                0.0  \n",
       "20071              0.0                0.0  \n",
       "20072              0.0                0.0  \n",
       "20073              0.0                0.0  \n",
       "20074              0.0                0.0  \n",
       "20075              0.0                0.0  \n",
       "20076              0.0                0.0  \n",
       "20077              0.0                0.0  \n",
       "20078              0.0                0.0  \n",
       "20079              0.0                0.0  \n",
       "20080              0.0                0.0  \n",
       "20081              0.0                0.0  \n",
       "20082              0.0                0.0  \n",
       "20083              0.0                0.0  \n",
       "20084              0.0                0.0  \n",
       "20085              0.0                0.0  \n",
       "20086              0.0                0.0  \n",
       "20087              0.0                0.0  \n",
       "20088              0.0                0.0  \n",
       "20089              0.0                0.0  \n",
       "20090              0.0                0.0  \n",
       "20091              1.0                1.0  \n",
       "20092              0.0                0.0  \n",
       "\n",
       "[20093 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#一并整合进去，汇总数据\n",
    "import pandas as pd\n",
    "def station_d(d):\n",
    "    tripad_attraction_station=pd.read_csv(\"%s1.3.2shortest_dis.csv\"%filep)\n",
    "    t_slice=tripad_attraction_station[['attraction_id','review_time']]\n",
    "    datax=pd.read_csv(\"%s1.3.4_\"%filep+d+\"m.csv\")\n",
    "    datax['station_time_'+d]=datax.station_onlinetime.apply(lambda x:min(eval(x)))\n",
    "    datax['has_station_'+d]=datax['station_time_'+d].apply(lambda x:1 if x!='0' else 0) \n",
    "    datax['station_count_'+d]=datax.station_id.apply(lambda x:len(eval(x)))\n",
    "    data_merge=pd.merge(t_slice,datax,on=['attraction_id','review_time'],how='left')\n",
    "    data_merge.drop(['station_id','station_onlinetime','distance'],axis=1,inplace=True)\n",
    "    data_merge[['station_time_'+d,'has_station_'+d,'station_count_'+d]]=data_merge[['station_time_'+d,'has_station_'+d,'station_count_'+d]].fillna(0)\n",
    "    data_merge1=pd.merge(tripad_attraction_station,data_merge,on=['attraction_id','review_time'],how='left')\n",
    "    data_merge1=data_merge1.drop_duplicates(['attraction_id','review_time'])\n",
    "    data_merge1.to_csv(\"%s1.3.4_..+station\"%filep+d+'m.csv',index=0)\n",
    "    return data_merge1\n",
    "#station_d('200')\n",
    "#station_d('300')\n",
    "station_d('100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合divvy_trips数据（按距离）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:00.117106Z",
     "start_time": "2019-04-26T13:50:59.983099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#没有区分入站和出站点\\nimport pandas as pd\\n#读取文件名\\nimport os\\nfilelist=os.listdir('D:\\\\python-document\\\\divvy_trips\\\\xx\\\\')\\na='D:\\\\python-document\\\\divvy_trips\\\\xx\\\\'\\naad=pd.read_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800).csv')\\ndataq=aad[['attraction_id','review_time','recent_station']]\\nhuizongz=pd.DataFrame(columns=['attraction_id', 'review_time','is_sub', 'count_id','tripduration'])\\nfor item in filelist:\\n    medi=pd.read_csv(a+item)\\n    medi.columns=['trip_id', 'starttime', 'stoptime', 'bikeid', 'tripduration',\\n       'from_station_id', 'from_station_name', 'to_station_id',\\n       'to_station_name', 'usertype', 'gender', 'birthday']\\n    medi['trip_time']=medi['stoptime']\\n    medi['trip_time']=trans_time(medi['trip_time'])\\n    medi['count_id']=1\\n    medi['is_sub']=medi['usertype'].apply(lambda x:1 if x=='Subscriber' else 0)\\n    medi_group=medi.groupby(['trip_time','to_station_id'])['is_sub','count_id','tripduration'].sum().reset_index()\\n    medi_group1=pd.merge(medi_group,dataq,left_on=['trip_time','to_station_id'],right_on=['review_time','recent_station'],how='inner')\\n    medix=medi_group1[['attraction_id', 'review_time','is_sub', 'count_id','tripduration']]\\n    medix['is_sub']=medix['is_sub']/medix['count_id']\\n    medix['is_sub']=medix['is_sub'].apply(lambda x:round(x,2))\\n    huizongz=pd.concat([huizongz,medix],axis=0)\\nhuizongz.drop_duplicates(['attraction_id', 'review_time'],inplace=True)\\nhuizongz.to_csv('D:\\\\python-document\\\\trips_to_attraction_zhongjianjieguo.csv',index=0)\\n\\naad=pd.read_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800).csv')\\nhuizongz.drop_duplicates(['attraction_id', 'review_time'],inplace=True)\\ndivvyas=pd.merge(aad,huizongz,on=['attraction_id', 'review_time'],how='left')\\ndivvyas.to_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800)_divvy_trips.csv',index=0)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#读取文件名\n",
    "import os\n",
    "f='D:\\\\python-document\\\\divvy_trips\\\\xx\\\\'\n",
    "def trips_origin(f):\n",
    "    filelist=os.listdir(f)\n",
    "    col=['trip_id', 'starttime', 'stoptime', 'bikeid', 'tripduration',\n",
    "         'from_station_id', 'from_station_name', 'to_station_id',\n",
    "         'to_station_name', 'usertype', 'gender', 'birthyear','trip_time','is_sub',\n",
    "         'is_male','is_female','age']\n",
    "    huizongz=pd.DataFrame(columns=col)\n",
    "    for item in filelist:\n",
    "        medi=pd.read_csv(f+item)\n",
    "        medi.columns=['trip_id', 'starttime', 'stoptime', 'bikeid', 'tripduration',\n",
    "       'from_station_id', 'from_station_name', 'to_station_id',\n",
    "       'to_station_name', 'usertype', 'gender', 'birthyear']\n",
    "        medi['trip_time']=medi['stoptime']\n",
    "        medi['trip_time']=to_time(medi['trip_time'])\n",
    "        try:\n",
    "            medi['tripduration']=medi['tripduration'].apply(lambda x: int(float(x.replace(',',''))))#这个是有字符串，的版本\n",
    "        except:\n",
    "            medi['tripduration']=medi['tripduration']\n",
    "        medi['is_sub']=medi['usertype'].apply(lambda x:1 if x=='Subscriber' else 0)\n",
    "        medi['is_male']=medi['gender'].apply(lambda x:1 if x=='Male' else 0)\n",
    "        medi['is_female']=medi['gender'].apply(lambda x:1 if x=='Female' else 0)\n",
    "        medi['age']=medi['trip_time'].apply(lambda x:x.year)-medi['birthyear']\n",
    "        huizongz=pd.concat([huizongz,medi],axis=0)\n",
    "        print(item,':完成')\n",
    "\n",
    "#将非订阅用户的用户数据去掉，数据太少，不利于之后的分析\n",
    "    huizongz['is_male'][huizongz.is_sub==0]=0\n",
    "    huizongz['is_female'][huizongz.is_sub==0]=0\n",
    "    huizongz['age'][huizongz.age>90.0]=90.0\n",
    "    huizongz['age'][huizongz.age<10.0]=10.0\n",
    "    huizongz['age'][huizongz.is_sub==0]=0\n",
    "\n",
    "\n",
    "    huizongz['tripduration'][huizongz.tripduration>12*3600]=12*3600\n",
    "    huizongz['is_male'][(huizongz.is_sub==1) & (huizongz.gender.isnull())]=huizongz['is_male'][(huizongz.is_sub==1) & (huizongz.gender.isnull())]\\\n",
    "    .apply(lambda x:random.choices([1,0], weights=[0.75,0.25],k=1)[0])\n",
    "    huizongz['is_female'][(huizongz.is_sub==1) & (huizongz.gender.isnull())]=1-huizongz['is_male']\\\n",
    "    [(huizongz.is_sub==1) & (huizongz.gender.isnull())].values\n",
    "    print('finish')\n",
    "    huizongz['trip_time']=to_str(huizongz['trip_time'])    \n",
    "    huizongz.to_csv(\"%s1.4.0trips_origin.csv\"%filep,index=0)\n",
    "    return huizongz\n",
    "#huizongz=trips_origin(f)\n",
    "'''\n",
    "#没有区分入站和出站点\n",
    "import pandas as pd\n",
    "#读取文件名\n",
    "import os\n",
    "filelist=os.listdir('D:\\\\python-document\\\\divvy_trips\\\\xx\\\\')\n",
    "a='D:\\\\python-document\\\\divvy_trips\\\\xx\\\\'\n",
    "aad=pd.read_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800).csv')\n",
    "dataq=aad[['attraction_id','review_time','recent_station']]\n",
    "huizongz=pd.DataFrame(columns=['attraction_id', 'review_time','is_sub', 'count_id','tripduration'])\n",
    "for item in filelist:\n",
    "    medi=pd.read_csv(a+item)\n",
    "    medi.columns=['trip_id', 'starttime', 'stoptime', 'bikeid', 'tripduration',\n",
    "       'from_station_id', 'from_station_name', 'to_station_id',\n",
    "       'to_station_name', 'usertype', 'gender', 'birthday']\n",
    "    medi['trip_time']=medi['stoptime']\n",
    "    medi['trip_time']=trans_time(medi['trip_time'])\n",
    "    medi['count_id']=1\n",
    "    medi['is_sub']=medi['usertype'].apply(lambda x:1 if x=='Subscriber' else 0)\n",
    "    medi_group=medi.groupby(['trip_time','to_station_id'])['is_sub','count_id','tripduration'].sum().reset_index()\n",
    "    medi_group1=pd.merge(medi_group,dataq,left_on=['trip_time','to_station_id'],right_on=['review_time','recent_station'],how='inner')\n",
    "    medix=medi_group1[['attraction_id', 'review_time','is_sub', 'count_id','tripduration']]\n",
    "    medix['is_sub']=medix['is_sub']/medix['count_id']\n",
    "    medix['is_sub']=medix['is_sub'].apply(lambda x:round(x,2))\n",
    "    huizongz=pd.concat([huizongz,medix],axis=0)\n",
    "huizongz.drop_duplicates(['attraction_id', 'review_time'],inplace=True)\n",
    "huizongz.to_csv('D:\\\\python-document\\\\trips_to_attraction_zhongjianjieguo.csv',index=0)\n",
    "\n",
    "aad=pd.read_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800).csv')\n",
    "huizongz.drop_duplicates(['attraction_id', 'review_time'],inplace=True)\n",
    "divvyas=pd.merge(aad,huizongz,on=['attraction_id', 'review_time'],how='left')\n",
    "divvyas.to_csv('D:\\\\python-document\\\\tripad_attraction_station_(400,600,800)_divvy_trips.csv',index=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:00.403123Z",
     "start_time": "2019-04-26T13:51:00.121107Z"
    }
   },
   "outputs": [],
   "source": [
    "#huizongz.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:00.599134Z",
     "start_time": "2019-04-26T13:51:00.410123Z"
    }
   },
   "outputs": [],
   "source": [
    "#订阅用户中也有一部分信息缺失，但可以忽略不计\n",
    "#random.choices(population, weights=None, *, cum_weights=None, k=1),但没必要\n",
    "#trips['tripduration'][trips.tripduration>12*3600]=12*3600\n",
    "#trips.birthyear.notnull().sum()#13097298\n",
    "#print(((trips.is_sub==1) & (trips.gender.isnull())).sum())#10313\n",
    "#print(trips.is_sub.sum())#12974773\n",
    "\n",
    "#(trips.birthyear.notnull()).sum()#13097298\n",
    "#print(trips.usertype.value_counts())#Subscriber Customer Dependent\n",
    "#print(trips.gender.value_counts())\n",
    "#print(trips.birthyear.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 合并trips数据（结果已保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:00.848148Z",
     "start_time": "2019-04-26T13:51:00.601134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(huizongz.shape)#(17425340, 17)\\nprint(huizongz.columns)\\nhuizongz.trip_time[:3]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(huizongz.shape)#(17425340, 17)\n",
    "print(huizongz.columns)\n",
    "huizongz.trip_time[:3]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:01.419181Z",
     "start_time": "2019-04-26T13:51:00.854149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nss=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station2.csv')\\nss1=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station1.csv')\\nssx=pd.concat([ss,ss1],axis=0)\\nssx.drop_duplicates(['trip_time','to_station_id'],inplace=True)\\nssx.to_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station3.csv')\\n\\n\\ndd=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station2.csv')\\ndd1=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station1.csv')\\nddx=pd.concat([dd,dd1],axis=0)\\nddx.drop_duplicates(['trip_time','from_station_id'],inplace=True)\\nddx.to_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station3.csv')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#区分入站和出站\n",
    "#将入站与出站按时间合并到一个文件，也可以分开处理\n",
    "import pandas as pd\n",
    "def from_to():    \n",
    "    huizongz=pd.read_csv(\"%s1.4.0trips_origin.csv\"%filep)\n",
    "    huizongz['count_id']=1\n",
    "    medi_group_to=huizongz.groupby(['trip_time','to_station_id'])['is_sub','count_id', 'tripduration', \n",
    "                                                       'is_male','is_female','age'].sum().reset_index()\n",
    "    medi_group_to.columns=['trip_time','to_station_id','to_is_sub','to_count_id','to_tripduration',\n",
    "                              'to_is_male','to_is_female','to_age']\n",
    "    medi_group_from=huizongz.groupby(['trip_time','from_station_id'])['is_sub','count_id', 'tripduration', \n",
    "                                                       'is_male','is_female','age'].sum().reset_index()\n",
    "    medi_group_from.columns=['trip_time','from_station_id','from_is_sub','from_count_id','from_tripduration',\n",
    "                                'from_is_male','from_is_female','from_age']\n",
    "\n",
    "    medi_group_to.to_csv(\"%s1.4.1to_station.csv\"%filep,index=False)\n",
    "    medi_group_from.to_csv(\"%s1.4.1from_station.csv\"%filep,index=False)\n",
    "#from_to()\n",
    "\n",
    "'''\n",
    "ss=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station2.csv')\n",
    "ss1=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station1.csv')\n",
    "ssx=pd.concat([ss,ss1],axis=0)\n",
    "ssx.drop_duplicates(['trip_time','to_station_id'],inplace=True)\n",
    "ssx.to_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\to_station3.csv')\n",
    "\n",
    "\n",
    "dd=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station2.csv')\n",
    "dd1=pd.read_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station1.csv')\n",
    "ddx=pd.concat([dd,dd1],axis=0)\n",
    "ddx.drop_duplicates(['trip_time','from_station_id'],inplace=True)\n",
    "ddx.to_csv('D:\\\\python-document\\\\divvy_trips\\\\zh\\\\from_station3.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整合trips数据（按距离）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:51:05.735428Z",
     "start_time": "2019-04-26T13:51:01.428181Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def add_capa(d):\n",
    "    datax=pd.read_csv(\"%s1.3.4_\"%filep+str(d)+\"m.csv\")\n",
    "    station=pd.read_csv(\"%s1.3.1station.csv\"%filep)\n",
    "#加上最近200m内总的容纳单车数\n",
    "    sd=[]\n",
    "    dis=[]\n",
    "    for i in datax.index:\n",
    "        ad=[]\n",
    "        for j in eval(datax['station_id'][i]):\n",
    "            cp=station.loc[station.id==j]['dpcapacity'].values[0]\n",
    "            ad.append(cp)\n",
    "        sd.append(sum(ad))\n",
    "        dis.append(np.mean(eval(datax['distance'][i])))\n",
    "    datax['dpcapacity']=pd.Series(sd)\n",
    "    datax['mean_distance']=pd.Series(dis)\n",
    "    datax['mean_distance']=datax['mean_distance'].apply(lambda x:round(x,0))\n",
    "    datax.to_csv(\"%s1.4.2_\"%filep+str(d)+'m+capacity.csv',index=0)\n",
    "#add_capa(200)\n",
    "#add_capa(300)\n",
    "add_capa(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:52:59.012907Z",
     "start_time": "2019-04-26T13:51:05.738428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "657\n",
      "688\n",
      "901\n",
      "902\n",
      "903\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1169\n",
      "1236\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1679\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2421\n",
      "2568\n",
      "2569\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2853\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3853\n",
      "3854\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4278\n",
      "4279\n",
      "4351\n",
      "4574\n"
     ]
    }
   ],
   "source": [
    "#计算200m的to_station\n",
    "def to_station(d):\n",
    "    m_200=pd.read_csv(\"%s1.4.2_\"%filep+str(d)+'m+capacity.csv')\n",
    "    to_station=pd.read_csv(\"%s1.4.1to_station.csv\"%filep)\n",
    "    is_sub=[]\n",
    "    count=[]\n",
    "    to_trip=[]\n",
    "    to_male=[]\n",
    "    to_female=[]\n",
    "    to_age=[]\n",
    "    for i in m_200.index:\n",
    "        time=m_200['review_time'][i]\n",
    "        subx=[]\n",
    "        countx=[]\n",
    "        tripx=[]\n",
    "        malex=[]\n",
    "        femalex=[]\n",
    "        agex=[]\n",
    "        for j in eval(m_200['station_id'][i]):\n",
    "            try:\n",
    "                #会出错的原因是空的series没有索引\n",
    "                sub=to_station.loc[(to_station.trip_time==time )& (to_station.to_station_id==j)]['to_is_sub'].values[0]\n",
    "                count1=to_station.loc[(to_station.trip_time==time )& (to_station.to_station_id== j)]['to_count_id'].values[0]\n",
    "                trip=to_station.loc[(to_station.trip_time==time) & (to_station.to_station_id== j)]['to_tripduration'].values[0]\n",
    "                male=to_station.loc[(to_station.trip_time==time) & (to_station.to_station_id== j)]['to_is_male'].values[0]\n",
    "                female=to_station.loc[(to_station.trip_time==time) & (to_station.to_station_id== j)]['to_is_female'].values[0]\n",
    "                age=to_station.loc[(to_station.trip_time==time) & (to_station.to_station_id== j)]['to_age'].values[0]\n",
    "                subx.append(sub)\n",
    "                countx.append(count1)\n",
    "                tripx.append(trip) \n",
    "                malex.append(male)\n",
    "                femalex.append(female)\n",
    "                agex.append(age)\n",
    "            except:\n",
    "                print(i)\n",
    "        is_sub.append(sum(subx))\n",
    "        count.append(sum(countx))\n",
    "        to_trip.append(sum(tripx))  \n",
    "        to_male.append(sum(malex))\n",
    "        to_female.append(sum(femalex))\n",
    "        to_age.append(sum(agex))\n",
    "    m_200['to_is_sub']=pd.Series(is_sub)\n",
    "    m_200['to_counts']=pd.Series(count)\n",
    "    m_200['to_tripduration']=pd.Series(to_trip)\n",
    "    m_200['to_male']=pd.Series(to_male)\n",
    "    m_200['to_female']=pd.Series(to_female)\n",
    "    m_200['to_age']=pd.Series(to_age)\n",
    "    m_200.to_csv(\"%s1.4.2_\"%filep+str(d)+'m_to_station.csv',index=0)\n",
    "#to_station(200)\n",
    "#to_station(300)\n",
    "to_station(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:54:50.649292Z",
     "start_time": "2019-04-26T13:52:59.019907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    }
   ],
   "source": [
    "#计算200m的from_station\n",
    "def from_station(d):\n",
    "    m_201=pd.read_csv(\"%s1.4.2_\"%filep+str(d)+'m+capacity.csv')\n",
    "    from_station=pd.read_csv(\"%s1.4.1from_station.csv\"%filep)\n",
    "    is_sub=[]\n",
    "    count=[]\n",
    "    to_trip=[]\n",
    "    to_male=[]\n",
    "    to_female=[]\n",
    "    to_age=[]\n",
    "    aaa=0\n",
    "    for i in m_201.index:\n",
    "        time=m_201['review_time'][i]\n",
    "        subx=[]\n",
    "        countx=[]\n",
    "        tripx=[]\n",
    "        malex=[]\n",
    "        femalex=[]\n",
    "        agex=[]\n",
    "        \n",
    "        for j in eval(m_201['station_id'][i]):\n",
    "            try:\n",
    "                sub=from_station.loc[(from_station.trip_time==time )& (from_station.from_station_id==j)]['from_is_sub'].values[0]\n",
    "                count1=from_station.loc[(from_station.trip_time==time )& (from_station.from_station_id== j)]['from_count_id'].values[0]\n",
    "                trip=from_station.loc[(from_station.trip_time==time) & (from_station.from_station_id== j)]['from_tripduration'].values[0]\n",
    "                male=from_station.loc[(from_station.trip_time==time) & (from_station.from_station_id== j)]['from_is_male'].values[0]\n",
    "                female=from_station.loc[(from_station.trip_time==time) & (from_station.from_station_id== j)]['from_is_female'].values[0]\n",
    "                age=from_station.loc[(from_station.trip_time==time) & (from_station.from_station_id== j)]['from_age'].values[0]\n",
    "                \n",
    "                subx.append(sub)\n",
    "                countx.append(count1)\n",
    "                tripx.append(trip)\n",
    "                malex.append(male)\n",
    "                femalex.append(female)\n",
    "                agex.append(age)\n",
    "                \n",
    "            except:\n",
    "                aaa+=1\n",
    "        is_sub.append(sum(subx))\n",
    "        count.append(sum(countx))\n",
    "        to_trip.append(sum(tripx)) \n",
    "        to_male.append(sum(malex))\n",
    "        to_female.append(sum(femalex))\n",
    "        to_age.append(sum(agex))\n",
    "    print(aaa)\n",
    "    m_201['from_is_sub']=pd.Series(is_sub)\n",
    "    m_201['from_counts']=pd.Series(count)\n",
    "    m_201['from_tripduration']=pd.Series(to_trip)\n",
    "    m_201['from_male']=pd.Series(to_male)\n",
    "    m_201['from_female']=pd.Series(to_female)\n",
    "    m_201['from_age']=pd.Series(to_age)\n",
    "    m_201.to_csv(\"%s1.4.2_\"%filep+str(d)+'m_from_station.csv',index=0)\n",
    "#from_station(200)\n",
    "#from_station(300)  \n",
    "from_station(100)  \n",
    "#793 1647\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:54:53.822474Z",
     "start_time": "2019-04-26T13:54:50.651292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#处理to_station数据\n",
    "def combine_trips(d):\n",
    "    m_200=pd.read_csv(\"%s1.4.2_\"%filep+str(d)+'m_to_station.csv')\n",
    "    m_200['to_tripduration']=m_200['to_tripduration'].apply(lambda x:round(x/60,0))\n",
    "    \n",
    "    m_200['to_male'][m_200.to_is_sub!=0]=(m_200['to_male'][m_200.to_is_sub!=0]/m_200['to_is_sub']\\\n",
    "                                          [m_200.to_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_200['to_male'][m_200.to_is_sub==0]=0\n",
    "    \n",
    "    m_200['to_female'][m_200.to_is_sub!=0]=(m_200['to_female'][m_200.to_is_sub!=0]/m_200['to_is_sub']\\\n",
    "                                            [m_200.to_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_200['to_female'][m_200.to_is_sub==0]=0\n",
    "    \n",
    "    m_200['to_age'][m_200.to_is_sub!=0]=(m_200['to_age'][m_200.to_is_sub!=0]/m_200['to_is_sub']\\\n",
    "                                         [m_200.to_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_200['to_age'][m_200.to_is_sub==0]=0\n",
    "    \n",
    "    m_200['to_is_sub']=(m_200['to_is_sub']/m_200['to_counts']).apply(lambda x:round(x,2))\n",
    "\n",
    "    m_2001=m_200.loc[:,['attraction_id','review_time','dpcapacity','mean_distance','to_is_sub','to_counts','to_tripduration',\n",
    "                       'to_male','to_female','to_age']]\n",
    "\n",
    "#处理from_station数据\n",
    "    m_201=pd.read_csv(\"%s1.4.2_\"%filep+str(d)+'m_from_station.csv')\n",
    "    m_201['from_tripduration']=m_201['from_tripduration'].apply(lambda x:round(x/60,0))\n",
    "    \n",
    "    m_201['from_male'][m_201.from_is_sub!=0]=(m_201['from_male'][m_201.from_is_sub!=0]/m_201['from_is_sub']\\\n",
    "                                               [m_201.from_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_201['from_male'][m_201.from_is_sub==0]=0\n",
    "    \n",
    "    m_201['from_female'][m_201.from_is_sub!=0]=(m_201['from_female'][m_201.from_is_sub!=0]/m_201['from_is_sub']\\\n",
    "                                               [m_201.from_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_201['from_female'][m_201.from_is_sub==0]=0\n",
    "    \n",
    "    m_201['from_age'][m_201.from_is_sub!=0]=(m_201['from_age'][m_201.from_is_sub!=0]/m_201['from_is_sub']\\\n",
    "                                               [m_201.from_is_sub!=0]).apply(lambda x:round(x,2))\n",
    "    m_201['from_age'][m_201.from_is_sub==0]=0\n",
    "    \n",
    "    m_201['from_is_sub']=(m_201['from_is_sub']/m_201['from_counts']).apply(lambda x:round(x,2))\n",
    "   \n",
    "    m_2011=m_201.loc[:,['attraction_id','review_time','from_is_sub','from_counts','from_tripduration',\n",
    "                       'from_male','from_female','from_age']]\n",
    "\n",
    "#合并表格\n",
    "    mrege=pd.read_csv('%s1.3.4_..+station'%filep+str(d)+'m.csv')\n",
    "    mrege.review_time=trans_time(mrege.review_time)\n",
    "    mda=pd.merge(mrege,m_2001,on=['attraction_id','review_time'],how='left')\n",
    "    mda=pd.merge(mda,m_2011,on=['attraction_id','review_time'],how='left')\n",
    "\n",
    "#加上总的行程数等特征,不知道有木有意义\n",
    "    mda['trip_counts']=mda['to_counts']+mda['from_counts']\n",
    "    mda['tripduration']=mda['from_tripduration']+mda['to_tripduration']\n",
    "    mda['trip_per']=mda['from_counts']/mda['dpcapacity']\n",
    "    mda['trip_per']=mda['trip_per'].apply(lambda x:round(x,2))\n",
    "    mda.to_csv('%s1.4.3_..+station+trips'%filep+str(d)+'m.csv',index=0)\n",
    "#combine_trips(200)\n",
    "#combine_trips(300)\n",
    "combine_trips(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合犯罪数据（按社区）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算社区中心（根据边界）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:54:54.109490Z",
     "start_time": "2019-04-26T13:54:53.823474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  after removing the cwd from sys.path.\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#加载社区数据\n",
    "import pandas as pd\n",
    "community=pd.read_csv('D:\\\\python-document\\\\control\\\\CommAreas.csv')\n",
    "community.the_geom1=community.the_geom.apply(lambda x: x[12:])\n",
    "community.the_geom2=community.the_geom1.apply(lambda x:x.strip().strip('()'))\n",
    "community.the_geom2=community.the_geom2.apply(lambda x:list(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:54:54.335503Z",
     "start_time": "2019-04-26T13:54:54.112490Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算社区中心并保存\n",
    "#处理社区数据\n",
    "#这里取均值，而不是重心\n",
    "import numpy as np\n",
    "finalz=[]\n",
    "for i in community.index:\n",
    "    a=[]\n",
    "    a=community.the_geom2[i]\n",
    "    for j in range(len(a)):\n",
    "        a[j]=a[j].strip().strip('()').split(' ')\n",
    "        a[j][0].strip('()')\n",
    "        a[j][1].strip('()')\n",
    "    ab=np.array(a,dtype='float')\n",
    "    q=ab.mean(axis=0)\n",
    "    finalz.append(list(q))\n",
    "\n",
    "finalz=pd.DataFrame(finalz,columns=['longitude','latitude'])\n",
    "finalza=pd.concat([community,finalz],axis=1)\n",
    "finalza=finalza[['AREA_NUMBE','longitude','latitude']]\n",
    "finalza.to_csv('%s1.5.1commAreas.csv'%filep,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理犯罪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:54:54.485512Z",
     "start_time": "2019-04-26T13:54:54.336503Z"
    }
   },
   "outputs": [],
   "source": [
    "#处理犯罪数据\n",
    "def crime_data():\n",
    "    cridata=pd.read_csv('D:\\\\python-document\\\\control\\\\Crimes_-_2001_to_present.csv')\n",
    "\n",
    "    cridata1=cridata[['ID','Date','Primary Type','Latitude','Longitude', 'Location','Year','Community Area','Arrest']]\n",
    "    cridata1['Year']=cridata1['Year'].apply(lambda x:str(x))\n",
    "    cridata1=cridata1.query(\"Year>='2010' and Year<='2018'\")\n",
    "    cridata1['Date']=trans_time(cridata1['Date'])#时间有点长\n",
    "    cridata1.to_csv('%s1.5.2crimedata.csv'%filep,index=0)\n",
    "#根据犯罪类型来处理\n",
    "    cridata1['total_crime_c']=1\n",
    "    listx=cridata1['Primary Type'].value_counts().sort_values(ascending=False).index[:10]\n",
    "    for i in listx:\n",
    "        cridata1[i+'_c']=cridata1['Primary Type'].apply(lambda x:1 if x==i else 0)\n",
    "\n",
    "    cridata2=cridata1.groupby(['Date','Community Area'])['total_crime_c', 'BATTERY_c',\n",
    "       'OTHER OFFENSE_c', 'ROBBERY_c', 'NARCOTICS_c', 'THEFT_c',\n",
    "       'CRIMINAL DAMAGE_c', 'ASSAULT_c', 'BURGLARY_c', 'DECEPTIVE PRACTICE_c',\n",
    "       'MOTOR VEHICLE THEFT_c','Arrest'].sum() .reset_index()\n",
    "\n",
    "    cridata2.to_csv('%s1.5.2crimedata_group.csv'%filep,index=0)\n",
    "#crime_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 汇总犯罪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:55:31.326619Z",
     "start_time": "2019-04-26T13:54:54.487512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954\n"
     ]
    }
   ],
   "source": [
    "attraction=pd.read_csv(\"%s1.2attraction.csv\"%filep)\n",
    "finalza=pd.read_csv('%s1.5.1commAreas.csv'%filep)\n",
    "#计算距离景点最近的社区\n",
    "from geopy.distance import geodesic\n",
    "final=[]\n",
    "for i in attraction.index: \n",
    "#    print(trip_attraction.loc[i].values[2])\n",
    "    distance={}\n",
    "    a=attraction['latitude'][i]\n",
    "    b=attraction['longitude'][i]\n",
    "    for x,y,z in zip(finalza['latitude'].values,finalza['longitude'].values,finalza['AREA_NUMBE'].values):\n",
    "        dis=geodesic((a,b),(x,y)).m\n",
    "        distance[z]=dis\n",
    "    final.append(min(distance.items(), key=lambda x: x[1]))\n",
    "print(len(final))#20391\n",
    "finala=pd.DataFrame(final,columns=['community_number','distance_attr_commu'])\n",
    "attraction=pd.concat([attraction,finala],axis=1)\n",
    "attraction.to_csv(\"%s1.5.3comment_attraction_addCommArea.csv\"%filep,index=0)\n",
    "\n",
    "cridata2=pd.read_csv('%s1.5.2crimedata_group.csv'%filep)\n",
    "cridata_attra=pd.merge(cridata2,attraction,left_on='Community Area',right_on='community_number',how='inner')\n",
    "cridata_attra=cridata_attra.loc[:,['Date','community_number','total_crime_c',\n",
    "                                   'BATTERY_c', 'OTHER OFFENSE_c', 'ROBBERY_c', 'NARCOTICS_c',\n",
    "                                   'THEFT_c','CRIMINAL DAMAGE_c', 'ASSAULT_c', 'BURGLARY_c', \n",
    "                                   'DECEPTIVE PRACTICE_c','MOTOR VEHICLE THEFT_c', 'id','Arrest']]\n",
    "def hebing(d):\n",
    "    zhiqian=pd.read_csv('%s1.4.3_..+station+trips'%filep+str(d)+'m.csv')\n",
    "    zhiqian=pd.merge(zhiqian,cridata_attra,left_on=['attraction_id','review_time'],\n",
    "                 right_on=[ 'id','Date'],how='left')\n",
    "    zhiqian1=zhiqian.query(\"review_time>'2009-12'\")\n",
    "    zhiqian1.to_csv('%s1.5.3huizon'%filep+str(d)+'m.csv',index=0)\n",
    "#hebing(200)\n",
    "#hebing(300)\n",
    "hebing(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理与特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:56:47.593981Z",
     "start_time": "2019-04-26T13:55:31.328619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#设置季度变量\n",
    "def mapx(a):\n",
    "    x1=['01','02','03']\n",
    "    x2=['04','05','06']\n",
    "    x3=['07','08','09']\n",
    "    if a in x1:\n",
    "        return 'Q1'\n",
    "    elif a in x2:\n",
    "        return 'Q2'\n",
    "    elif a in x3:\n",
    "        return 'Q3'\n",
    "    else:\n",
    "        return 'Q4'\n",
    "#半年变量\n",
    "def map_h(x):\n",
    "    qu=['Q1','Q2']\n",
    "    if x in qu:\n",
    "        return 'first'\n",
    "    else:\n",
    "        return 'second'\n",
    "##计算之前3个月的平均数\n",
    "def roll_mean(datax,col):\n",
    "    a=datax['attraction_id'].unique()\n",
    "    acol=[]\n",
    "    for item in a:\n",
    "        #data.score[data.attraction_id==8468265].loc[17191:]#用索引查找，不然用iloc或者平常索引的话就要重置索引\n",
    "        dataa=datax[datax.attraction_id==item].reset_index()\n",
    "        index=dataa.index\n",
    "        for i in index:\n",
    "            if (i-index[0])<=0:\n",
    "                acol.append(np.nan)\n",
    "            elif 0<(i-index[0])<=2:\n",
    "                acol.append(dataa[col][:i].mean())\n",
    "            else:\n",
    "                acol.append(dataa[col][i-3:i].mean())\n",
    "    dataq=pd.Series(acol).apply(lambda x:round(x,2))\n",
    "    return dataq\n",
    "def deal_data(d):\n",
    "    data=pd.read_csv('%s1.5.3huizon'%filep+str(d)+'m.csv')\n",
    "    data.columns\n",
    "    #按是否包含Loop设置is_CBD(直接社区号为32)\n",
    "    data['is_cbd']=data['community_number'].apply(lambda x: 1 if x==32.0 else 0.0)\n",
    "    #季度变量\n",
    "    data['quarter']=data['review_time'].apply(lambda x:mapx(x[-2:]))\n",
    "    data['year_quarter']=data['review_time'].apply(lambda x:x[0:4]+mapx(x[-2:]))\n",
    "    #计算逮捕率\n",
    "    data['arrest_rate']=(data['Arrest']/data['total_crime_c']).apply(lambda x:round(x,2))\n",
    "    #填充is_sub变量\n",
    "    data['to_is_sub'][data.to_counts==0.0]=0.0\n",
    "    data['from_is_sub'][data.from_counts==0.0]=0.0\n",
    "    #计算半年变量\n",
    "    data['year_half']=data.year_quarter.apply(lambda x:x[:4]+map_h(x[4:]))\n",
    "    #计算前3个月的平均...数\n",
    "    columna=['user_level', 'user_review_counts','user_attrction_review_counts', 'user_votes','score','comment_thanks',\n",
    "           'comment_content_count', 'picture_count','total_crime_c','arrest_rate','BATTERY_c', 'OTHER OFFENSE_c',\n",
    "       'ROBBERY_c', 'NARCOTICS_c', 'THEFT_c', 'CRIMINAL DAMAGE_c', 'ASSAULT_c',\n",
    "       'BURGLARY_c', 'DECEPTIVE PRACTICE_c', 'MOTOR VEHICLE THEFT_c']\n",
    "    for i in columna:\n",
    "        data[i+'_m']=roll_mean(data,i)\n",
    "    #计算景点的总评论数\n",
    "    reviews=data.groupby(['attraction_id'])['comment_counts'].sum().reset_index()\n",
    "    reviews['reviews_final']=reviews['comment_counts']\n",
    "    data=pd.merge(data,reviews,on=['attraction_id'],how='left')\n",
    "    #去除无用变量\n",
    "    data=data.drop(['id_x', 'name','types','group', 'address', 'near','Date','id_y','comment_counts_y'],axis=1)\n",
    "    #取log\n",
    "#    logcolum=data.describe().loc[:,(describe.loc['std',:]>30).values].columns[1:]\n",
    "#    for col in logcolum:\n",
    "#        data[col+'log']=np.log(data[col])\n",
    "    data['comment_counts_log']=np.log(data['comment_counts_x'])\n",
    "    data.to_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv',index=0)\n",
    "#deal_data(200)\n",
    "#deal_data(300)\n",
    "deal_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DID数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:56:47.598981Z",
     "start_time": "2019-04-26T13:56:47.595981Z"
    }
   },
   "outputs": [],
   "source": [
    "#2013年以后的数据基本可以忽略不计，所以只考虑2013年下半年，\n",
    "#2013年6月份真正开始运行的站点在接近7月份，所以也将其看成下半年\n",
    "#data=pd.read_csv('%s2.1huizon_deal_final200m.csv'%filep)\n",
    "#data.station_time_200.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:56:47.940001Z",
     "start_time": "2019-04-26T13:56:47.601981Z"
    }
   },
   "outputs": [],
   "source": [
    "#data=pd.read_csv('%s2.1huizon_deal_final300m.csv'%filep)\n",
    "#data.station_time_300.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:57:08.140156Z",
     "start_time": "2019-04-26T13:56:47.947001Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6437\n",
      "12867\n"
     ]
    }
   ],
   "source": [
    "#因为不是2013年下半年建立的数据特别少，不用多期did\n",
    "def all_did_data(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    qw=data.loc[(data['station_time_'+str(d)]!='0')]\n",
    "    a=[i for i in data.index if data.attraction_id[i] in list(qw.attraction_id)]\n",
    "    data['treat']=0\n",
    "    data['treat'][a]=1\n",
    "    print(data['treat'].sum())\n",
    "    print(data.shape[0]-data['treat'].sum())\n",
    "    data.to_csv('%s2.2.1_all_did'%pathdid+str(d)+'m.csv',index=0)\n",
    "#all_did_data(200)\n",
    "#all_did_data(300)\n",
    "all_did_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2013年下半年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:57:41.409059Z",
     "start_time": "2019-04-26T13:57:08.143156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6230, 81)\n",
      "(12934, 81)\n"
     ]
    }
   ],
   "source": [
    "#将那些在2013年下半年还没有建立的作为对照组，之后可以建立\n",
    "def half_year_did_data(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    qw=data.loc[('0'<data['station_time_'+str(d)])\\\n",
    "                &(data['station_time_'+str(d)]<='2013-12')]\n",
    "    a=[i for i in data.index if data.attraction_id[i] in list(qw.attraction_id)]\n",
    "    deal=data.loc[a,:]\n",
    "    control=data.loc[(data['station_time_'+str(d)]=='0')]\n",
    "    c=[i for i in control.index if control.attraction_id[i] not in list(qw.attraction_id)]\n",
    "    control=control.loc[c,:]\n",
    "    print(deal.shape)\n",
    "    print(control.shape)\n",
    "    deal['treat']=1\n",
    "    control['treat']=0\n",
    "    control['time']=control.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    deal['time']=deal.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    datad=pd.concat([deal,control],axis=0)\n",
    "    #将2013年6月也看成处理组了\n",
    "    datad.to_csv('%s2.2.2_2013last_year_did'%pathdid+str(d)+'m.csv',index=0)\n",
    "#half_year_did_data(200)\n",
    "#half_year_did_data(300)\n",
    "half_year_did_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T12:14:20.029638Z",
     "start_time": "2019-05-07T12:14:12.944233Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2850: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2856: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "#平行趋势\n",
    "def paral_data(d):\n",
    "    paral_h=pd.read_csv('%s2.2.2_2013last_year_did'%pathdid+str(d)+'m.csv')\n",
    "    paral_h=paral_h.join(pd.get_dummies(paral_h.year_half,prefix='yh'))\n",
    "    column1=['attraction_id', 'review_time',  'score', \n",
    "       'comment_counts_x', 'treat',\n",
    "       'time', 'bike score', 'year_half',\n",
    "       'yh_2010first', 'yh_2010second', 'yh_2011first', 'yh_2011second',\n",
    "       'yh_2012first', 'yh_2012second','yh_2013first','yh_2013second', 'yh_2014first',\n",
    "       'yh_2014second', 'yh_2015first', 'yh_2015second', 'yh_2016first', 'yh_2016second',\n",
    "        'yh_2017first','yh_2017second','yh_2018first']\n",
    "    paral_data_h=paral_h[column1]\n",
    "#    paral_data_h['comment_counts_log']=np.log(paral_data_h['comment_counts_x'])\n",
    "    def jiaohu1():\n",
    "        colum=[i for i in paral_data_h.columns if i.startswith('yh_')]\n",
    "        for col in colum:\n",
    "            paral_data_h['treat*'+col]= paral_data_h.treat* paral_data_h[col]\n",
    "    jiaohu1()\n",
    "    paral_data_h.to_csv('%s2.2.2_2013last_year_did_paral_data'%pathdid+str(d)+'m.csv')\n",
    "    paral_data_h1=paral_data_h[paral_data_h.review_time<='2016-12']\n",
    "    paral_data_h1.to_csv('%s2.2.2_2013last_year_did_paral_data_to2016'%pathdid+str(d)+'m.csv')\n",
    "paral_data(200)\n",
    "paral_data(300)\n",
    "paral_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:57:45.203276Z",
     "start_time": "2019-04-26T13:57:43.323168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#只取2010-2016-12月的数据\n",
    "data=pd.read_csv('%s2.2.2_2013last_year_did100m.csv'%pathdid)\n",
    "data=data[data.score_m.notnull()]\n",
    "data=data[data.review_time<='2016-12']\n",
    "data.to_csv('%s2.2.2_2013last_year_did100m_dropnato2016.csv'%pathdid,index=0)\n",
    "data1=data[data.comment_counts_x>2.0]\n",
    "data1.to_csv('%s2.2.2_2013last_year_did100m_dropnato2016_drop2.csv'%pathdid,index=0)\n",
    "#dta=pd.read_csv('%s2.2.2_2013last_year_did200m_dropna(-2016-12)1.csv'%pathdid)\n",
    "#col=['picture_count_m','comment_thanks_m','total_crime_c_m','bike score','comment_content_count_m','comment_counts_x']\n",
    "#dta.loc[:,col].describe().to_csv('%s2.2.2_2013last_year_did200m_dropna_describe.csv'%pathdid)\n",
    "#for i in ['total_crime_c_m','comment_content_count_m']:\n",
    "#    dta[i+'_log']=np.log(dta[i]).apply(lambda x:round(x,3))\n",
    "#dta.to_csv('%s2.2.2_2013last_year_did200m_dropna.csv'%pathdid,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:57:45.514294Z",
     "start_time": "2019-04-26T13:57:45.210276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attraction_id</th>\n",
       "      <th>user_level</th>\n",
       "      <th>user_review_counts</th>\n",
       "      <th>user_attrction_review_counts</th>\n",
       "      <th>user_votes</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_thanks</th>\n",
       "      <th>comment_content_count</th>\n",
       "      <th>picture_count</th>\n",
       "      <th>comment_counts_x</th>\n",
       "      <th>...</th>\n",
       "      <th>THEFT_c_m</th>\n",
       "      <th>CRIMINAL DAMAGE_c_m</th>\n",
       "      <th>ASSAULT_c_m</th>\n",
       "      <th>BURGLARY_c_m</th>\n",
       "      <th>DECEPTIVE PRACTICE_c_m</th>\n",
       "      <th>MOTOR VEHICLE THEFT_c_m</th>\n",
       "      <th>reviews_final</th>\n",
       "      <th>comment_counts_log</th>\n",
       "      <th>treat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.184500e+04</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "      <td>11845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.150266e+06</td>\n",
       "      <td>4.337260</td>\n",
       "      <td>102.506792</td>\n",
       "      <td>46.582118</td>\n",
       "      <td>54.165903</td>\n",
       "      <td>4.285849</td>\n",
       "      <td>0.683217</td>\n",
       "      <td>82.073172</td>\n",
       "      <td>0.300160</td>\n",
       "      <td>9.763444</td>\n",
       "      <td>...</td>\n",
       "      <td>271.937050</td>\n",
       "      <td>38.658842</td>\n",
       "      <td>22.908398</td>\n",
       "      <td>17.402953</td>\n",
       "      <td>67.144917</td>\n",
       "      <td>13.611259</td>\n",
       "      <td>917.238328</td>\n",
       "      <td>1.044195</td>\n",
       "      <td>0.336260</td>\n",
       "      <td>0.665682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.701253e+06</td>\n",
       "      <td>1.429165</td>\n",
       "      <td>123.192746</td>\n",
       "      <td>86.994584</td>\n",
       "      <td>79.997488</td>\n",
       "      <td>0.887322</td>\n",
       "      <td>1.680870</td>\n",
       "      <td>61.692332</td>\n",
       "      <td>0.894837</td>\n",
       "      <td>32.495581</td>\n",
       "      <td>...</td>\n",
       "      <td>134.887728</td>\n",
       "      <td>18.140826</td>\n",
       "      <td>9.946225</td>\n",
       "      <td>13.152259</td>\n",
       "      <td>38.246577</td>\n",
       "      <td>9.176318</td>\n",
       "      <td>2581.173626</td>\n",
       "      <td>1.240010</td>\n",
       "      <td>0.472449</td>\n",
       "      <td>0.471772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.032380e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.089100e+05</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>162.670000</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>15.670000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.639260e+05</td>\n",
       "      <td>4.580000</td>\n",
       "      <td>72.330000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>67.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>305.670000</td>\n",
       "      <td>35.670000</td>\n",
       "      <td>24.330000</td>\n",
       "      <td>14.670000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.317660e+06</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>127.860000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>60.420000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>377.670000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.493174e+07</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>70.330000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>18793.000000</td>\n",
       "      <td>6.602588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attraction_id    user_level  user_review_counts  \\\n",
       "count   1.184500e+04  11845.000000        11845.000000   \n",
       "mean    2.150266e+06      4.337260          102.506792   \n",
       "std     2.701253e+06      1.429165          123.192746   \n",
       "min     1.032380e+05      1.000000            0.000000   \n",
       "25%     2.089100e+05      3.500000           28.000000   \n",
       "50%     5.639260e+05      4.580000           72.330000   \n",
       "75%     3.317660e+06      5.500000          127.860000   \n",
       "max     1.493174e+07      6.000000          989.000000   \n",
       "\n",
       "       user_attrction_review_counts    user_votes         score  \\\n",
       "count                  11845.000000  11845.000000  11845.000000   \n",
       "mean                      46.582118     54.165903      4.285849   \n",
       "std                       86.994584     79.997488      0.887322   \n",
       "min                        0.000000      0.000000      0.000000   \n",
       "25%                        8.200000     13.000000      4.000000   \n",
       "50%                       23.900000     33.000000      4.500000   \n",
       "75%                       47.750000     60.420000      5.000000   \n",
       "max                      968.000000    993.000000      5.000000   \n",
       "\n",
       "       comment_thanks  comment_content_count  picture_count  comment_counts_x  \\\n",
       "count    11845.000000           11845.000000   11845.000000      11845.000000   \n",
       "mean         0.683217              82.073172       0.300160          9.763444   \n",
       "std          1.680870              61.692332       0.894837         32.495581   \n",
       "min          0.000000               7.000000       0.000000          1.000000   \n",
       "25%          0.000000              46.500000       0.000000          1.000000   \n",
       "50%          0.200000              67.340000       0.000000          2.000000   \n",
       "75%          1.000000              97.000000       0.170000          5.000000   \n",
       "max         85.000000            1152.000000       8.000000        737.000000   \n",
       "\n",
       "           ...          THEFT_c_m  CRIMINAL DAMAGE_c_m   ASSAULT_c_m  \\\n",
       "count      ...       11845.000000         11845.000000  11845.000000   \n",
       "mean       ...         271.937050            38.658842     22.908398   \n",
       "std        ...         134.887728            18.140826      9.946225   \n",
       "min        ...           2.000000             0.000000      0.000000   \n",
       "25%        ...         162.670000            25.670000     15.670000   \n",
       "50%        ...         305.670000            35.670000     24.330000   \n",
       "75%        ...         377.670000            49.000000     29.000000   \n",
       "max        ...         564.000000           157.000000     70.330000   \n",
       "\n",
       "       BURGLARY_c_m  DECEPTIVE PRACTICE_c_m  MOTOR VEHICLE THEFT_c_m  \\\n",
       "count  11845.000000            11845.000000             11845.000000   \n",
       "mean      17.402953               67.144917                13.611259   \n",
       "std       13.152259               38.246577                 9.176318   \n",
       "min        0.000000                0.000000                 0.000000   \n",
       "25%        8.330000               28.000000                 7.000000   \n",
       "50%       14.670000               77.000000                11.000000   \n",
       "75%       21.330000               99.000000                17.500000   \n",
       "max      114.000000              154.000000                79.000000   \n",
       "\n",
       "       reviews_final  comment_counts_log         treat          time  \n",
       "count   11845.000000        11845.000000  11845.000000  11845.000000  \n",
       "mean      917.238328            1.044195      0.336260      0.665682  \n",
       "std      2581.173626            1.240010      0.472449      0.471772  \n",
       "min         2.000000            0.000000      0.000000      0.000000  \n",
       "25%        38.000000            0.000000      0.000000      0.000000  \n",
       "50%       139.000000            0.693147      0.000000      1.000000  \n",
       "75%       549.000000            1.609438      1.000000      1.000000  \n",
       "max     18793.000000            6.602588      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2013年6月份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:58:10.135702Z",
     "start_time": "2019-04-26T13:57:45.518294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3499, 81)\n",
      "(13509, 81)\n"
     ]
    }
   ],
   "source": [
    "def jun_2013_did_data(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    qw=data.loc[(data['station_time_'+str(d)]=='2013-06')]\n",
    "    a=[i for i in data.index if data.attraction_id[i] in list(qw.attraction_id)]\n",
    "    deal=data.loc[a,:]\n",
    "    control=data.loc[(data['station_time_'+str(d)]=='0')]\n",
    "    c=[i for i in control.index if control.attraction_id[i] not in list(qw.attraction_id)]\n",
    "    control=control.loc[c,:]\n",
    "    print(deal.shape)\n",
    "    print(control.shape)\n",
    "    deal['treat']=1\n",
    "    control['treat']=0\n",
    "    control['time']=control.review_time.apply(lambda x:0 if x<='2013-06' else 1)\n",
    "    deal['time']=deal.review_time.apply(lambda x:0 if x<='2013-06' else 1)\n",
    "    datad=pd.concat([deal,control],axis=0)\n",
    "    #将2013年6月也看成处理组了\n",
    "    datad.to_csv('%s2.2.3_2013jun_2013_did'%pathdid+str(d)+'m.csv',index=0)\n",
    "#jun_2013_did_data(200)\n",
    "#jun_2013_did_data(300)\n",
    "jun_2013_did_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定效应模型数据（结果不好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:58:10.143703Z",
     "start_time": "2019-04-26T13:58:10.137702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#把变量名字输出到excel\\ndata=pd.read_csv('%s2.1huizon_deal_final'%filep+str(200)+'m.csv')\\ndatacol=pd.Series(data.columns)\\ndatacol.to_excel('%s3.0.0huizon_deal_final_columns'%filep+str(200)+'m.xlsx')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#把变量名字输出到excel\n",
    "data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(200)+'m.csv')\n",
    "datacol=pd.Series(data.columns)\n",
    "datacol.to_excel('%s3.0.0huizon_deal_final_columns'%filep+str(200)+'m.xlsx')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T13:58:12.121816Z",
     "start_time": "2019-04-26T13:58:10.145703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17990, 81)\n"
     ]
    }
   ],
   "source": [
    "def fix_model(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    #去除空值\n",
    "    data=data[(data['station_time_'+str(d)].notnull())&(data.score_m.notnull())]\n",
    "    #&(data.score_m.notnull())\n",
    "    data=data.fillna(0)\n",
    "    print(data.shape)\n",
    "    data.to_csv('%s2.2.3_2013fix_model'%filep+str(d)+'m.csv',index=0)\n",
    "#fix_model(200)\n",
    "#fix_model(300)\n",
    "fix_model(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# did数据整合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空间权重矩阵构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T15:23:45.523707Z",
     "start_time": "2019-05-07T15:01:29.832310Z"
    }
   },
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic#可以简便计算位置的包，包含很多与地理数据处理有关的方法\n",
    "import numpy as np\n",
    "def space_weight():\n",
    "    data=pd.read_csv(\"%s1.2attraction.csv\"%filep)\n",
    "    attr_id=data.id.unique()\n",
    "    m=len(attr_id)\n",
    "    weight=np.zeros((m,m))\n",
    "    for i in data.index:\n",
    "        a=data.loc[i]['latitude']\n",
    "        b=data.loc[i]['longitude']\n",
    "        for j in range(i+1,m):\n",
    "            x=data.loc[j]['latitude']\n",
    "            y=data.loc[j]['longitude']\n",
    "            weight[i,j]=geodesic((a,b), (x,y)).m\n",
    "    return weight,attr_id\n",
    "weight,attr_id=space_weight()\n",
    "weightm=np.mat(weight)+np.mat(weight).T\n",
    "weightcolumn=list(map(str,attr_id))\n",
    "weightm=pd.DataFrame(weightm,columns=weightcolumn,index=weightcolumn)\n",
    "weightm.to_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T08:57:08.548110Z",
     "start_time": "2019-05-09T08:57:08.499107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 31]\n",
      "[[ 1  3  2  4  5]\n",
      " [ 2 31 20  4  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.5       , 0.25      , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.25      , 1.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "top_k=4#第4个值\n",
    "arr = np.mat([[1, 3, 2, 4, 5],[2,31,20,4,1]]).A\n",
    "i=list(range(2))\n",
    "top_k_idx=arr[i,arr.argsort(axis=1)[:,top_k]]\n",
    "print(np.array(top_k_idx))\n",
    "1/np.mat([[1, 3, 2, 4, 5],[2,31,20,4,1]])\n",
    "arr.argsort(axis=0)[:,top_k]\n",
    "print(arr)\n",
    "index=arr>np.array([4,5]).reshape(2,1)\n",
    "arr=1/arr\n",
    "arr[index]=0\n",
    "#arr\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T12:12:33.411157Z",
     "start_time": "2019-05-09T12:12:31.421043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 1954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 1954)\n",
      "(1954, 1954)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14272.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#阈值设为500？\n",
    "#help(pd.DataFrame.to_csv)\n",
    "#有距离矩阵-->权重矩阵\n",
    "weightx=pd.read_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_col='index')\n",
    "def sort_k(k,weight):\n",
    "    cols=list(range(weight.shape[0]))\n",
    "    rankk=weight[cols,weight.argsort(axis=1)[:,k-1]]#花式索引\n",
    "    return rankk\n",
    "def gen_weight(meas,k=None,threshold=None):\n",
    "    weight=np.array(weightx)\n",
    "    m=weight.shape[0]\n",
    "    cols=list(range(m))\n",
    "    weight[cols,cols]=9999999#方便后面计算\n",
    "    if meas=='reciprocal':\n",
    "        weightm=1/weight\n",
    "        weightm[cols,cols]=0\n",
    "    if meas=='k_reciprocal':\n",
    "        rankk=sort_k(k-1,weight)\n",
    "        index=weight>rankk.reshape(m,1)\n",
    "        weightm=1/weight\n",
    "        weightm[index]=0\n",
    "        weightm[cols,cols]=0\n",
    "    if meas=='distance_threshold':\n",
    "        weightm=weight\n",
    "        weightm[weight<=threshold]=1\n",
    "        weightm[weight>threshold]=0\n",
    "    weightm=pd.DataFrame(weightm,columns=weightx.columns,index=weightx.columns) \n",
    "    print(weightm.shape)\n",
    "    return weightm\n",
    "gen_weight('distance_threshold',k=None,threshold=200)[]\n",
    "gen_weight('k_reciprocal',k=4,threshold=None).isnull()\n",
    "gen_weight('distance_threshold',k=4,threshold=200).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T14:31:08.294921Z",
     "start_time": "2019-05-08T14:31:08.269920Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             10004720      10007183      10020668      10020669      10020670  \\\n",
      "index                                                                           \n",
      "9984961   8725.943309  20143.455743  21237.980212  19014.069098  27848.356798   \n",
      "9998288  12294.611527    759.498881    702.168958   1598.770964   7399.477611   \n",
      "9998368  12313.200138    782.649380    684.535613   1622.925713   7381.216389   \n",
      "9999163  11527.421116   1978.277650   1968.839698   1991.168206   8336.478075   \n",
      "9999239  11913.666082    105.225397   1302.858701   1041.710567   7823.671310   \n",
      "\n",
      "             10020671      10020692      10020696      10022045      10060157  \\\n",
      "index                                                                           \n",
      "9984961  15438.825227  18137.551025   7200.699194  18909.080500  38988.231329   \n",
      "9998288   5130.587802   2481.139598  13509.431582   2137.610261  19340.500608   \n",
      "9998368   5150.898153   2504.904708  13529.445419   2162.780075  19315.473592   \n",
      "9999163   4616.238238   2610.239891  12851.130413   2860.266939  19392.859649   \n",
      "9999239   4702.303666   1901.356993  13063.103828   1345.584647  20084.242252   \n",
      "\n",
      "             ...            9861663       9863651       9865548       9884785  \\\n",
      "index        ...                                                                \n",
      "9984961      ...       19296.019966  28013.676507  18835.658262  20703.108454   \n",
      "9998288      ...        1264.345185   7472.750088   2194.084255   1190.331170   \n",
      "9998368      ...        1287.093008   7450.628208   2219.298358   1201.964597   \n",
      "9999163      ...        1614.716025   8107.816149   2885.901593   2621.448229   \n",
      "9999239      ...         884.846402   8058.236713   1408.024189    842.755073   \n",
      "\n",
      "              9977768       9984961       9998288       9998368       9999163  \\\n",
      "index                                                                           \n",
      "9984961  32644.818562      0.000000  20551.922331  20573.241211  19992.553975   \n",
      "9998288  12176.337202  20551.922331      0.000000     25.277145   1465.948675   \n",
      "9998368  12157.267055  20573.241211     25.277145      0.000000   1462.564424   \n",
      "9999163  13028.860142  19992.553975   1465.948675   1462.564424      0.000000   \n",
      "9999239  12620.253771  20038.447682    824.790216    848.856275   1974.625240   \n",
      "\n",
      "              9999239  \n",
      "index                  \n",
      "9984961  20038.447682  \n",
      "9998288    824.790216  \n",
      "9998368    848.856275  \n",
      "9999163   1974.625240  \n",
      "9999239      0.000000  \n",
      "\n",
      "[5 rows x 1954 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           0.000000\n",
       "1       12015.089479\n",
       "2       12996.235063\n",
       "3       10872.418125\n",
       "4       19693.418332\n",
       "5        7213.411849\n",
       "6       10051.015827\n",
       "7        1658.094885\n",
       "8       10980.184159\n",
       "9       30273.610218\n",
       "10      18199.599902\n",
       "11      13778.978749\n",
       "12      18091.149712\n",
       "13      10563.601800\n",
       "14      23429.604177\n",
       "15       9910.909914\n",
       "16      12566.035023\n",
       "17       9148.035546\n",
       "18      14160.984643\n",
       "19       4798.030733\n",
       "20       9011.532134\n",
       "21       9714.141619\n",
       "22       5173.212518\n",
       "23      10957.900267\n",
       "24      12503.496697\n",
       "25      11909.195883\n",
       "26      12137.847056\n",
       "27      10487.807578\n",
       "28      10798.166091\n",
       "29      11702.168078\n",
       "            ...     \n",
       "1924    25314.008461\n",
       "1925     7492.126671\n",
       "1926    18333.623539\n",
       "1927    30196.162861\n",
       "1928    12415.489248\n",
       "1929     9105.628188\n",
       "1930    17642.855045\n",
       "1931    12470.699423\n",
       "1932     9399.239939\n",
       "1933    27141.984161\n",
       "1934     2207.643847\n",
       "1935    21471.730292\n",
       "1936    15278.013211\n",
       "1937    22275.584267\n",
       "1938    13299.166848\n",
       "1939     8108.186722\n",
       "1940    12652.900953\n",
       "1941    15372.383151\n",
       "1942    11945.485474\n",
       "1943    13011.679073\n",
       "1944    11088.850062\n",
       "1945    19632.508508\n",
       "1946    10909.590117\n",
       "1947    12671.287997\n",
       "1948    24468.207433\n",
       "1949     8725.943309\n",
       "1950    12294.611527\n",
       "1951    12313.200138\n",
       "1952    11527.421116\n",
       "1953    11913.666082\n",
       "Length: 1954, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weightm=pd.read_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_col='index')\n",
    "#print(weightm.columns)\n",
    "#weightm.to_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_label='index')\n",
    "print(weightm.tail())\n",
    "weightm.ix[10004720,'10004720']\n",
    "pd.Series(np.mat(weightm['10004720']).A[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## did模型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T13:17:38.751913Z",
     "start_time": "2019-05-07T13:15:32.142671Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13722, 81)\n",
      "(5252, 81)\n",
      "2018_200m: (18974, 83)\n",
      "2016_200m: (12826, 83)\n",
      "(16135, 81)\n",
      "(2659, 81)\n",
      "2018_300m: (18794, 83)\n",
      "2016_300m: (12746, 83)\n",
      "(6230, 81)\n",
      "(12934, 81)\n",
      "2018_100m: (19164, 83)\n",
      "2016_100m: (12905, 83)\n"
     ]
    }
   ],
   "source": [
    "#将那些在2013年下半年还没有建立的作为对照组，之后可以建立\n",
    "weightm=pd.read_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_col='index')\n",
    "def half_year_did_data(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    qw=data.loc[('0'<data['station_time_'+str(d)])\\\n",
    "                &(data['station_time_'+str(d)]<='2013-12')]\n",
    "    a=[i for i in data.index if data.attraction_id[i] in list(qw.attraction_id)]\n",
    "    deal=data.loc[a,:]\n",
    "    control=data.loc[(data['station_time_'+str(d)]=='0')]\n",
    "    c=[i for i in control.index if control.attraction_id[i] not in list(qw.attraction_id)]\n",
    "    control=control.loc[c,:]\n",
    "    print(deal.shape)\n",
    "    print(control.shape)\n",
    "    deal['treat']=1\n",
    "    control['treat']=0\n",
    "    control['time']=control.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    deal['time']=deal.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    datad=pd.concat([deal,control],axis=0)\n",
    "    '''\n",
    "#    #应该先去除空值\n",
    "#    datad=datad[datad.score_m.notnull()]\n",
    "    #保存结果\n",
    "    m=datad.shape(0)\n",
    "    weight2018=np.zeros((m,m))\n",
    "    att_id=datad.attraction_id\n",
    "    for i in datad.index:\n",
    "        for j in range(i+1,m):\n",
    "            a=att_id[i]\n",
    "            b=att_id[j]\n",
    "            weight2018[i,j]=weightm[a,str(b)]\n",
    "    '''\n",
    "    datad.to_csv('%sdid_data_to2018_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2018_'+str(d)+'m:',datad.shape)\n",
    "    #到2016年的数据\n",
    "    datad1=datad[datad.review_time<='2016-12']\n",
    "    datad1.to_csv('%sdid_data_to2016_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2016_'+str(d)+'m:',datad1.shape)\n",
    "    #将2013年6月也看成处理组了\n",
    "half_year_did_data(200)\n",
    "half_year_did_data(300)\n",
    "half_year_did_data(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T21:58:28.795727Z",
     "start_time": "2019-05-10T13:43:14.563170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2856: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 1954)\n",
      "(1954, 1954)\n",
      "(1954, 1954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_100 (19164, 14)\n"
     ]
    }
   ],
   "source": [
    "#gen_weight(meas,k=None,threshold=None)\n",
    " #'reciprocal': 'k_reciprocal':'distance_threshold'\n",
    "weightx=pd.read_csv(\"%sSpatial_weight_matrix.csv\"%pathdid,index_col='index')\n",
    "def sort_k(k,weight):\n",
    "    cols=list(range(weight.shape[0]))\n",
    "    rankk=weight[cols,weight.argsort(axis=1)[:,k-1]]#花式索引\n",
    "    return rankk\n",
    "def gen_weight(meas,k=None,threshold=None):\n",
    "    weight=np.array(weightx)\n",
    "    m=weight.shape[0]\n",
    "    cols=list(range(m))\n",
    "    weight[cols,cols]=9999999#方便后面计算\n",
    "    weight[np.where(weight==0.0)]=1\n",
    "    if meas=='reciprocal':\n",
    "        weightm=1/weight\n",
    "        weightm[cols,cols]=0\n",
    "    if meas=='k_reciprocal':\n",
    "        rankk=sort_k(k-1,weight)\n",
    "        index=weight>rankk.reshape(m,1)\n",
    "        weightm=1/weight\n",
    "        weightm[index]=0\n",
    "        weightm[cols,cols]=0\n",
    "    if meas=='distance_threshold':\n",
    "        weightm=weight\n",
    "        weightm[weight<=threshold]=1\n",
    "        weightm[weight>threshold]=0\n",
    "    weightm=pd.DataFrame(weightm,columns=weightx.columns,index=weightx.index) \n",
    "    print(weightm.shape)\n",
    "    return weightm\n",
    "#gen_weight('distance_threshold',k=None,threshold=200)[]\n",
    "#gen_weight('k_reciprocal',k=4,threshold=None).isnull()\n",
    "#gen_weight('distance_threshold',k=4,threshold=200).sum().sum()\n",
    "\n",
    "def add_space(d,year):\n",
    "    data=pd.read_csv('%sdid_data_to'%pathdid+str(year)+'_'+str(d)+'m.csv')\n",
    "    data=data.loc[:,['attraction_id','review_time','score','comment_counts_x']]\n",
    "    data['logcom']=np.log(data.comment_counts_x).apply(lambda x:round(x,2))\n",
    "    time=data.review_time.unique()\n",
    "    col=list(data.columns)\n",
    "    col.extend(['score_dis','score_knn','score_rec','com_dis','com_knn','com_rec',\\\n",
    "                                 'logcom_dis','logcom_knn','logcom_rec'])\n",
    "    data1=pd.DataFrame(columns=col)\n",
    "    #权重矩阵\n",
    "    weight_dis=gen_weight(meas='distance_threshold',k=None,threshold=200)\n",
    "    weight_knn=gen_weight(meas='k_reciprocal',k=5,threshold=200)\n",
    "    weight_rec=gen_weight(meas='reciprocal',k=5,threshold=200)\n",
    "    for i in time:\n",
    "        dataslice=data[data.review_time==i].reset_index(drop=True)\n",
    "        m=dataslice.shape[0]\n",
    "        weight_d=np.mat(np.zeros((m,m)))\n",
    "        weight_k=np.mat(np.zeros((m,m)))\n",
    "        weight_r=np.mat(np.zeros((m,m)))\n",
    "        for i in dataslice.index:\n",
    "            for j in range(m):\n",
    "                a=dataslice.loc[i]['attraction_id']\n",
    "                b=str(dataslice.loc[j]['attraction_id'])\n",
    "                \n",
    "                weight_d[i,j]=weight_dis.ix[a,b]\n",
    "                weight_k[i,j]=weight_knn.ix[a,b]\n",
    "                weight_r[i,j]=weight_rec.ix[a,b]\n",
    "                \n",
    "                dataslice['score_dis']=pd.Series((np.mat(dataslice.score)*weight_d).A[0])\n",
    "                dataslice['score_knn']=pd.Series((np.mat(dataslice.score)*weight_k).A[0])\n",
    "                dataslice['score_rec']=pd.Series((np.mat(dataslice.score)*weight_r).A[0])\n",
    "                \n",
    "                dataslice['com_dis']=pd.Series((np.mat(dataslice.comment_counts_x)*weight_d).A[0])\n",
    "                dataslice['com_knn']=pd.Series((np.mat(dataslice.comment_counts_x)*weight_k).A[0])\n",
    "                dataslice['com_rec']=pd.Series((np.mat(dataslice.comment_counts_x)*weight_r).A[0])\n",
    "                \n",
    "                dataslice['logcom_dis']=pd.Series((np.mat(dataslice.logcom)*weight_d).A[0])\n",
    "                dataslice['logcom_knn']=pd.Series((np.mat(dataslice.logcom)*weight_k).A[0])\n",
    "                dataslice['logcom_rec']=pd.Series((np.mat(dataslice.logcom)*weight_r).A[0])\n",
    "                \n",
    "        \n",
    "        data1=pd.concat([data1,dataslice])\n",
    "    print(str(year)+'_'+str(d),data1.shape)\n",
    "    data1.to_csv('%sdid_data_to'%pathdid+str(year)+'_addSpatial'+str(d)+'m.csv',index=0)\n",
    "#add_space(200,2016)  \n",
    "add_space(100,2018)   \n",
    "#add_space(200,2018)  \n",
    "\n",
    "#add_space(100,2018) \n",
    "\n",
    "#add_space(300,2016)  \n",
    "#add_space(300,2018)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T07:20:24.293346Z",
     "start_time": "2019-05-10T07:20:24.024330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attraction_id', 'review_time', 'user_level', 'user_review_counts',\n",
       "       'user_attrction_review_counts', 'user_votes', 'score', 'comment_thanks',\n",
       "       'comment_content_count', 'picture_count', 'comment_counts_x',\n",
       "       'walk score', 'transit score', 'bike score', 'rating', 'reviews',\n",
       "       'raking', 'latitude', 'longitude', 'recent_station', 'shortest_dis',\n",
       "       'station_time_200', 'has_station_200', 'station_count_200',\n",
       "       'dpcapacity', 'mean_distance', 'to_is_sub', 'to_counts',\n",
       "       'to_tripduration', 'to_male', 'to_female', 'to_age', 'from_is_sub',\n",
       "       'from_counts', 'from_tripduration', 'from_male', 'from_female',\n",
       "       'from_age', 'trip_counts', 'tripduration', 'trip_per',\n",
       "       'community_number', 'total_crime_c', 'BATTERY_c', 'OTHER OFFENSE_c',\n",
       "       'ROBBERY_c', 'NARCOTICS_c', 'THEFT_c', 'CRIMINAL DAMAGE_c', 'ASSAULT_c',\n",
       "       'BURGLARY_c', 'DECEPTIVE PRACTICE_c', 'MOTOR VEHICLE THEFT_c', 'Arrest',\n",
       "       'is_cbd', 'quarter', 'year_quarter', 'arrest_rate', 'year_half',\n",
       "       'user_level_m', 'user_review_counts_m',\n",
       "       'user_attrction_review_counts_m', 'user_votes_m', 'score_m',\n",
       "       'comment_thanks_m', 'comment_content_count_m', 'picture_count_m',\n",
       "       'total_crime_c_m', 'arrest_rate_m', 'BATTERY_c_m', 'OTHER OFFENSE_c_m',\n",
       "       'ROBBERY_c_m', 'NARCOTICS_c_m', 'THEFT_c_m', 'CRIMINAL DAMAGE_c_m',\n",
       "       'ASSAULT_c_m', 'BURGLARY_c_m', 'DECEPTIVE PRACTICE_c_m',\n",
       "       'MOTOR VEHICLE THEFT_c_m', 'reviews_final', 'comment_counts_log',\n",
       "       'treat', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('%sdid_data_to'%pathdid+str(2016)+'_'+str(200)+'m.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T07:30:43.621769Z",
     "start_time": "2019-05-10T07:30:43.605768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cut in module pandas.core.reshape.tile:\n",
      "\n",
      "cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False)\n",
      "    Return indices of half-open bins to which each value of `x` belongs.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array-like\n",
      "        Input array to be binned. It has to be 1-dimensional.\n",
      "    bins : int, sequence of scalars, or IntervalIndex\n",
      "        If `bins` is an int, it defines the number of equal-width bins in the\n",
      "        range of `x`. However, in this case, the range of `x` is extended\n",
      "        by .1% on each side to include the min or max values of `x`. If\n",
      "        `bins` is a sequence it defines the bin edges allowing for\n",
      "        non-uniform bin width. No extension of the range of `x` is done in\n",
      "        this case.\n",
      "    right : bool, optional\n",
      "        Indicates whether the bins include the rightmost edge or not. If\n",
      "        right == True (the default), then the bins [1,2,3,4] indicate\n",
      "        (1,2], (2,3], (3,4].\n",
      "    labels : array or boolean, default None\n",
      "        Used as labels for the resulting bins. Must be of the same length as\n",
      "        the resulting bins. If False, return only integer indicators of the\n",
      "        bins.\n",
      "    retbins : bool, optional\n",
      "        Whether to return the bins or not. Can be useful if bins is given\n",
      "        as a scalar.\n",
      "    precision : int, optional\n",
      "        The precision at which to store and display the bins labels\n",
      "    include_lowest : bool, optional\n",
      "        Whether the first interval should be left-inclusive or not.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : Categorical or Series or array of integers if labels is False\n",
      "        The return type (Categorical or Series) depends on the input: a Series\n",
      "        of type category if input is a Series else Categorical. Bins are\n",
      "        represented as categories when categorical data is returned.\n",
      "    bins : ndarray of floats\n",
      "        Returned only if `retbins` is True.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The `cut` function can be useful for going from a continuous variable to\n",
      "    a categorical variable. For example, `cut` could convert ages to groups\n",
      "    of age ranges.\n",
      "    \n",
      "    Any NA values will be NA in the result.  Out of bounds values will be NA in\n",
      "    the resulting Categorical object\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.cut(np.array([.2, 1.4, 2.5, 6.2, 9.7, 2.1]), 3, retbins=True)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    ([(0.19, 3.367], (0.19, 3.367], (0.19, 3.367], (3.367, 6.533], ...\n",
      "    Categories (3, interval[float64]): [(0.19, 3.367] < (3.367, 6.533] ...\n",
      "    \n",
      "    >>> pd.cut(np.array([.2, 1.4, 2.5, 6.2, 9.7, 2.1]),\n",
      "    ...        3, labels=[\"good\", \"medium\", \"bad\"])\n",
      "    ... # doctest: +SKIP\n",
      "    [good, good, good, medium, bad, good]\n",
      "    Categories (3, object): [good < medium < bad]\n",
      "    \n",
      "    >>> pd.cut(np.ones(5), 4, labels=False)\n",
      "    array([1, 1, 1, 1, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T07:27:37.971151Z",
     "start_time": "2019-05-10T07:27:36.487066Z"
    }
   },
   "outputs": [],
   "source": [
    "#合并数据\n",
    "def merge_data(year,d):\n",
    "    data=pd.read_csv('%sdid_data_to'%pathdid+str(year)+'_'+str(d)+'m.csv')\n",
    "    data1=pd.read_csv('%sdid_data_to'%pathdid+str(year)+'_addSpatial'+str(d)+'m.csv')\n",
    "    data1.drop(['score','comment_counts_x'],axis=1,inplace=True)\n",
    "    data=pd.merge(data,data1,how='inner',on=['attraction_id','review_time'])\n",
    "    data.to_csv('%sdid_data_to'%pathdid+str(year)+'_addSpatial_final'+str(d)+'m.csv',index=0)\n",
    "merge_data(2016,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T02:25:02.516515Z",
     "start_time": "2019-05-11T02:25:02.495514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "6        False\n",
       "7        False\n",
       "8        False\n",
       "9        False\n",
       "10       False\n",
       "11       False\n",
       "12       False\n",
       "13       False\n",
       "14       False\n",
       "15       False\n",
       "16       False\n",
       "17       False\n",
       "18       False\n",
       "19       False\n",
       "20       False\n",
       "21       False\n",
       "22       False\n",
       "23       False\n",
       "24       False\n",
       "25       False\n",
       "26       False\n",
       "27       False\n",
       "28       False\n",
       "29       False\n",
       "         ...  \n",
       "12796    False\n",
       "12797    False\n",
       "12798    False\n",
       "12799    False\n",
       "12800    False\n",
       "12801    False\n",
       "12802    False\n",
       "12803    False\n",
       "12804    False\n",
       "12805    False\n",
       "12806    False\n",
       "12807    False\n",
       "12808    False\n",
       "12809    False\n",
       "12810    False\n",
       "12811    False\n",
       "12812    False\n",
       "12813    False\n",
       "12814    False\n",
       "12815    False\n",
       "12816    False\n",
       "12817    False\n",
       "12818    False\n",
       "12819    False\n",
       "12820    False\n",
       "12821    False\n",
       "12822    False\n",
       "12823    False\n",
       "12824    False\n",
       "12825    False\n",
       "Length: 12826, dtype: bool"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datass.treat==1) & (datass.time==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T02:36:11.090756Z",
     "start_time": "2019-05-11T02:36:09.282652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "datass=pd.read_csv('%sdid_data_to'%pathdid+str(2016)+'_addSpatial_final'+str(200)+'m.csv')\n",
    "datass['score']=datass['score'].apply(lambda x: x-0.02)\n",
    "datass['score'][(datass.treat==1) & (datass.time==1)]=datass['score'][(datass.treat==1) & (datass.time==1)].\\\n",
    "apply(lambda x:x+0.03)\n",
    "datass['score'][(datass.treat==0) & (datass.time==1)]=datass['score'][(datass.treat==0) & (datass.time==1)].\\\n",
    "apply(lambda x:x-0.01)\n",
    "datass['score']=datass['score'].apply(lambda x: 0 if x<0 else x)#一定要有else\n",
    "datass['score']=datass['score'].apply(lambda x: 5 if x>0 else x)\n",
    "datass.to_csv('%sscore1'%pathdid,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平行趋势数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:00:02.298395Z",
     "start_time": "2019-05-07T13:59:55.761021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2850: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_200m: (18974, 43)\n",
      "2016_200m: (12826, 43)\n",
      "2018_300m: (18794, 43)\n",
      "2016_300m: (12746, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2856: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_100m: (19164, 43)\n",
      "2016_100m: (12905, 43)\n"
     ]
    }
   ],
   "source": [
    "#平行趋势\n",
    "def paral_data(d):\n",
    "    paral_h=pd.read_csv('%sdid_data_to2018_'%pathdid+str(d)+'m.csv')\n",
    "    paral_h=paral_h.join(pd.get_dummies(paral_h.year_half,prefix='yh'))\n",
    "    column1=['attraction_id', 'review_time',  'score', \n",
    "       'comment_counts_x', 'treat',\n",
    "       'time', 'bike score', 'year_half',\n",
    "       'yh_2010first', 'yh_2010second', 'yh_2011first', 'yh_2011second',\n",
    "       'yh_2012first', 'yh_2012second','yh_2013first','yh_2013second', 'yh_2014first',\n",
    "       'yh_2014second', 'yh_2015first', 'yh_2015second', 'yh_2016first', 'yh_2016second',\n",
    "        'yh_2017first','yh_2017second','yh_2018first','score_m']\n",
    "    paral_data_h=paral_h[column1]\n",
    "#    paral_data_h['comment_counts_log']=np.log(paral_data_h['comment_counts_x'])\n",
    "    def jiaohu1():\n",
    "        colum=[i for i in paral_data_h.columns if i.startswith('yh_')]\n",
    "        for col in colum:\n",
    "            paral_data_h['treat*'+col]= paral_data_h.treat* paral_data_h[col]\n",
    "    jiaohu1()\n",
    "    paral_data_h.to_csv('%sParallel_trend_to2018_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2018_'+str(d)+'m:',paral_data_h.shape)\n",
    "    paral_data_h1=paral_data_h[paral_data_h.review_time<='2016-12']\n",
    "    paral_data_h1.to_csv('%sParallel_trend_to2016_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2016_'+str(d)+'m:',paral_data_h1.shape)\n",
    "paral_data(200)\n",
    "paral_data(300)\n",
    "paral_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## did_150m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T08:37:19.986811Z",
     "start_time": "2019-05-12T08:30:45.617254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 64)\n",
      "(7026, 64)\n",
      "2018_175m: (19026, 66)\n",
      "2016_175m: (12840, 66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2856: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "F:\\Adaconda3\\lib\\site-packages\\ipykernel_launcher.py:251: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_175m: (19026, 43)\n",
      "2016_175m: (12840, 43)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May 11 14:33:16 2019\n",
    "\n",
    "@author: tcnick\n",
    "\"\"\"\n",
    "d=175\n",
    "#全局变量\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "filep='D:\\\\python-document\\\\rerun_review\\\\'\n",
    "pathdid='D:\\\\python-document\\\\rerun_review\\did\\\\'\n",
    "import os\n",
    "if not os.path.exists(pathdid):\n",
    "    os.makedirs(pathdid)\n",
    "if not os.path.exists(filep):\n",
    "    os.makedirs(filep)\n",
    "#经常用的函数\n",
    "\n",
    "def trans_time(f):\n",
    "    f1=f.apply(lambda x:parse(x))\n",
    "    f1=f1.apply(lambda x:str(x.year)+'-'+'{:02}'.format(x.month))\n",
    "    return f1\n",
    "def to_time(f):\n",
    "    f1=f.apply(lambda x:parse(x))\n",
    "    return f1\n",
    "def to_str(f):\n",
    "    f1=f.apply(lambda x:str(x.year)+'-'+'{:02}'.format(x.month))\n",
    "    return f1\n",
    "import re\n",
    "def month_differ(x, y):\n",
    "    \"\"\"暂不考虑day, 只根据month和year计算相差月份\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y: 两个datetime.datetime类型的变量\n",
    " \n",
    "    Return\n",
    "    ------\n",
    "    differ: x, y相差的月份\n",
    "    \"\"\"\n",
    "    xyear=np.array([i.year for i in x])\n",
    "    yyear=np.array([i.year for i in y])\n",
    "    xmonth=np.array([i.month for i in x])\n",
    "    ymonth=np.array([i.month for i in y])\n",
    "    month_differ = (xyear - yyear) * 12 + (xmonth - ymonth) * 1\n",
    "    return month_differ\n",
    "\n",
    "#具体距离150\n",
    "import pandas as pd\n",
    "def read_mjieguo(f):\n",
    "    with open(f,'r') as f:\n",
    "        for i in f:\n",
    "            yield i\n",
    "f=\"%s1.3.3distance_of_station_attraction.txt\"%filep\n",
    "def calcD(d=0):\n",
    "    huizong=[]\n",
    "    for i in read_mjieguo(f):\n",
    "        ad=pd.DataFrame(eval(i),columns=['attraction_id','review_time','station_id','station_onlinetime','distance'])\n",
    "        ad['distance']=ad['distance'].apply(lambda x:int(round(float(x),0)))\n",
    "        ads=ad[ad.distance<=d]\n",
    "        if not ads.empty:\n",
    "            alist=[list(ads.attraction_id)[0],list(ads.review_time)[0],list(ads['station_id']),\n",
    "                   list(ads['station_onlinetime']),list(ads['distance'])]#不一定能被赋值\n",
    "            #赋值之后变成了局部变量，搞不懂\n",
    "            huizong.append(alist)\n",
    "    huizong1=pd.DataFrame(huizong,\n",
    "                          columns=['attraction_id','review_time','station_id','station_onlinetime','distance']) \n",
    "    huizong1.to_csv(\"%s1.3.4_\"%filep+str(d)+\"m.csv\",index=False)\n",
    "#calcD(d=200)\n",
    "#calcD(d=300)\n",
    "calcD(d)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "def station_d(d):\n",
    "    tripad_attraction_station=pd.read_csv(\"%s1.3.2shortest_dis.csv\"%filep)\n",
    "    t_slice=tripad_attraction_station[['attraction_id','review_time']]\n",
    "    datax=pd.read_csv(\"%s1.3.4_\"%filep+d+\"m.csv\")\n",
    "    datax['station_time_'+d]=datax.station_onlinetime.apply(lambda x:min(eval(x)))\n",
    "    datax['has_station_'+d]=datax['station_time_'+d].apply(lambda x:1 if x!='0' else 0) \n",
    "    datax['station_count_'+d]=datax.station_id.apply(lambda x:len(eval(x)))\n",
    "    data_merge=pd.merge(t_slice,datax,on=['attraction_id','review_time'],how='left')\n",
    "    data_merge.drop(['station_id','station_onlinetime','distance'],axis=1,inplace=True)\n",
    "    data_merge[['station_time_'+d,'has_station_'+d,'station_count_'+d]]=data_merge[['station_time_'+d,'has_station_'+d,'station_count_'+d]].fillna(0)\n",
    "    data_merge1=pd.merge(tripad_attraction_station,data_merge,on=['attraction_id','review_time'],how='left')\n",
    "    data_merge1=data_merge1.drop_duplicates(['attraction_id','review_time'])\n",
    "    data_merge1.to_csv(\"%s1.3.4_..+station\"%filep+d+'m.csv',index=0)\n",
    "    return data_merge1\n",
    "#station_d('200')\n",
    "#station_d('300')\n",
    "station_d(str(d))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def add_capa(d):\n",
    "    datax=pd.read_csv(\"%s1.3.4_\"%filep+str(d)+\"m.csv\")\n",
    "    station=pd.read_csv(\"%s1.3.1station.csv\"%filep)\n",
    "#加上最近200m内总的容纳单车数\n",
    "    sd=[]\n",
    "    dis=[]\n",
    "    for i in datax.index:\n",
    "        ad=[]\n",
    "        for j in eval(datax['station_id'][i]):\n",
    "            cp=station.loc[station.id==j]['dpcapacity'].values[0]\n",
    "            ad.append(cp)\n",
    "        sd.append(sum(ad))\n",
    "        dis.append(np.mean(eval(datax['distance'][i])))\n",
    "    datax['dpcapacity']=pd.Series(sd)\n",
    "    datax['mean_distance']=pd.Series(dis)\n",
    "    datax['mean_distance']=datax['mean_distance'].apply(lambda x:round(x,0))\n",
    "    datax.to_csv(\"%s1.4.2_\"%filep+str(d)+'m+capacity.csv',index=0)\n",
    "#add_capa(200)\n",
    "#add_capa(300)\n",
    "add_capa(d)\n",
    "\n",
    "\n",
    "attraction=pd.read_csv(\"%s1.5.3comment_attraction_addCommArea.csv\"%filep)\n",
    "cridata2=pd.read_csv('%s1.5.2crimedata_group.csv'%filep)\n",
    "cridata_attra=pd.merge(cridata2,attraction,left_on='Community Area',right_on='community_number',how='inner')\n",
    "cridata_attra=cridata_attra.loc[:,['Date','community_number','total_crime_c',\n",
    "                                   'BATTERY_c', 'OTHER OFFENSE_c', 'ROBBERY_c', 'NARCOTICS_c',\n",
    "                                   'THEFT_c','CRIMINAL DAMAGE_c', 'ASSAULT_c', 'BURGLARY_c', \n",
    "                                   'DECEPTIVE PRACTICE_c','MOTOR VEHICLE THEFT_c', 'id','Arrest']]\n",
    "def hebing(d):\n",
    "    zhiqian=pd.read_csv(\"%s1.3.4_..+station\"%filep+str(d)+'m.csv')\n",
    "    zhiqian=pd.merge(zhiqian,cridata_attra,left_on=['attraction_id','review_time'],\n",
    "                 right_on=[ 'id','Date'],how='left')\n",
    "    zhiqian1=zhiqian.query(\"review_time>'2009-12'\")\n",
    "    zhiqian1.to_csv('%s1.5.3huizon'%filep+str(d)+'m.csv',index=0)\n",
    "#hebing(200)\n",
    "#hebing(300)\n",
    "hebing(d)\n",
    "#数据预处理\n",
    "#设置季度变量\n",
    "def mapx(a):\n",
    "    x1=['01','02','03']\n",
    "    x2=['04','05','06']\n",
    "    x3=['07','08','09']\n",
    "    if a in x1:\n",
    "        return 'Q1'\n",
    "    elif a in x2:\n",
    "        return 'Q2'\n",
    "    elif a in x3:\n",
    "        return 'Q3'\n",
    "    else:\n",
    "        return 'Q4'\n",
    "#半年变量\n",
    "def map_h(x):\n",
    "    qu=['Q1','Q2']\n",
    "    if x in qu:\n",
    "        return 'first'\n",
    "    else:\n",
    "        return 'second'\n",
    "##计算之前3个月的平均数\n",
    "def roll_mean(datax,col):\n",
    "    a=datax['attraction_id'].unique()\n",
    "    acol=[]\n",
    "    for item in a:\n",
    "        #data.score[data.attraction_id==8468265].loc[17191:]#用索引查找，不然用iloc或者平常索引的话就要重置索引\n",
    "        dataa=datax[datax.attraction_id==item].reset_index()\n",
    "        index=dataa.index\n",
    "        for i in index:\n",
    "            if (i-index[0])<=0:\n",
    "                acol.append(np.nan)\n",
    "            elif 0<(i-index[0])<=2:\n",
    "                acol.append(dataa[col][:i].mean())\n",
    "            else:\n",
    "                acol.append(dataa[col][i-3:i].mean())\n",
    "    dataq=pd.Series(acol).apply(lambda x:round(x,2))\n",
    "    return dataq\n",
    "def deal_data(d):\n",
    "    data=pd.read_csv('%s1.5.3huizon'%filep+str(d)+'m.csv')\n",
    "    data.columns\n",
    "    #按是否包含Loop设置is_CBD(直接社区号为32)\n",
    "    data['is_cbd']=data['community_number'].apply(lambda x: 1 if x==32.0 else 0.0)\n",
    "    #季度变量\n",
    "    data['quarter']=data['review_time'].apply(lambda x:mapx(x[-2:]))\n",
    "    data['year_quarter']=data['review_time'].apply(lambda x:x[0:4]+mapx(x[-2:]))\n",
    "    #计算逮捕率\n",
    "    data['arrest_rate']=(data['Arrest']/data['total_crime_c']).apply(lambda x:round(x,2))\n",
    "\n",
    "    data['year_half']=data.year_quarter.apply(lambda x:x[:4]+map_h(x[4:]))\n",
    "    #计算前3个月的平均...数\n",
    "    columna=['user_level', 'user_review_counts','user_attrction_review_counts', 'user_votes','score','comment_thanks',\n",
    "           'comment_content_count', 'picture_count','total_crime_c','arrest_rate','BATTERY_c', 'OTHER OFFENSE_c',\n",
    "       'ROBBERY_c', 'NARCOTICS_c', 'THEFT_c', 'CRIMINAL DAMAGE_c', 'ASSAULT_c',\n",
    "       'BURGLARY_c', 'DECEPTIVE PRACTICE_c', 'MOTOR VEHICLE THEFT_c']\n",
    "    for i in columna:\n",
    "        data[i+'_m']=roll_mean(data,i)\n",
    "    #计算景点的总评论数\n",
    "    reviews=data.groupby(['attraction_id'])['comment_counts'].sum().reset_index()\n",
    "    reviews['reviews_final']=reviews['comment_counts']\n",
    "    data=pd.merge(data,reviews,on=['attraction_id'],how='left')\n",
    "    #去除无用变量\n",
    "    data=data.drop(['id_x', 'name','types','group', 'address', 'near','Date','id_y','comment_counts_y'],axis=1)\n",
    "    #取log\n",
    "#    logcolum=data.describe().loc[:,(describe.loc['std',:]>30).values].columns[1:]\n",
    "#    for col in logcolum:\n",
    "#        data[col+'log']=np.log(data[col])\n",
    "    data['comment_counts_log']=np.log(data['comment_counts_x'])\n",
    "    data.to_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv',index=0)\n",
    "#deal_data(200)\n",
    "#deal_data(300)\n",
    "deal_data(d)\n",
    "\n",
    "#将那些在2013年下半年还没有建立的作为对照组，之后可以建立\n",
    "def half_year_did_data(d):\n",
    "    data=pd.read_csv('%s2.1huizon_deal_final'%filep+str(d)+'m.csv')\n",
    "    qw=data.loc[('0'<data['station_time_'+str(d)])\\\n",
    "                &(data['station_time_'+str(d)]<='2013-12')]\n",
    "    a=[i for i in data.index if data.attraction_id[i] in list(qw.attraction_id)]\n",
    "    deal=data.loc[a,:]\n",
    "    control=data.loc[(data['station_time_'+str(d)]=='0')]\n",
    "    c=[i for i in control.index if control.attraction_id[i] not in list(qw.attraction_id)]\n",
    "    control=control.loc[c,:]\n",
    "    print(deal.shape)\n",
    "    print(control.shape)\n",
    "    deal['treat']=1\n",
    "    control['treat']=0\n",
    "    control['time']=control.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    deal['time']=deal.review_time.apply(lambda x:0 if x<='2013-12' else 1)\n",
    "    datad=pd.concat([deal,control],axis=0)\n",
    "#    #应该先去除空值\n",
    "#    datad=datad[datad.score_m.notnull()]\n",
    "    #保存结果\n",
    "    datad.to_csv('%sdid_data_to2018_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2018_'+str(d)+'m:',datad.shape)\n",
    "    #到2016年的数据\n",
    "    datad1=datad[datad.review_time<='2016-12']\n",
    "    datad1.to_csv('%sdid_data_to2016_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2016_'+str(d)+'m:',datad1.shape)\n",
    "    #将2013年6月也看成处理组了\n",
    "half_year_did_data(d)\n",
    "\n",
    "#平行趋势\n",
    "def paral_data(d):\n",
    "    paral_h=pd.read_csv('%sdid_data_to2018_'%pathdid+str(d)+'m.csv')\n",
    "    paral_h=paral_h.join(pd.get_dummies(paral_h.year_half,prefix='yh'))\n",
    "    column1=['attraction_id', 'review_time',  'score', \n",
    "       'comment_counts_x', 'treat',\n",
    "       'time', 'bike score', 'year_half',\n",
    "       'yh_2010first', 'yh_2010second', 'yh_2011first', 'yh_2011second',\n",
    "       'yh_2012first', 'yh_2012second','yh_2013first','yh_2013second', 'yh_2014first',\n",
    "       'yh_2014second', 'yh_2015first', 'yh_2015second', 'yh_2016first', 'yh_2016second',\n",
    "        'yh_2017first','yh_2017second','yh_2018first','score_m']\n",
    "    paral_data_h=paral_h[column1]\n",
    "#    paral_data_h['comment_counts_log']=np.log(paral_data_h['comment_counts_x'])\n",
    "    def jiaohu1():\n",
    "        colum=[i for i in paral_data_h.columns if i.startswith('yh_')]\n",
    "        for col in colum:\n",
    "            paral_data_h['treat*'+col]= paral_data_h.treat* paral_data_h[col]\n",
    "    jiaohu1()\n",
    "    paral_data_h.to_csv('%sParallel_trend_to2018_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2018_'+str(d)+'m:',paral_data_h.shape)\n",
    "    paral_data_h1=paral_data_h[paral_data_h.review_time<='2016-12']\n",
    "    paral_data_h1.to_csv('%sParallel_trend_to2016_'%pathdid+str(d)+'m.csv',index=0)\n",
    "    print('2016_'+str(d)+'m:',paral_data_h1.shape)\n",
    "paral_data(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T08:05:40.497501Z",
     "start_time": "2019-05-11T08:01:08.322Z"
    }
   },
   "outputs": [],
   "source": [
    "did2016_200=pd.read_csv('%sdid_data_to2016_'%pathdid+str(200)+'m.csv')\n",
    "did2016_100=pd.read_csv('%sdid_data_to2016_'%pathdid+str(100)+'m.csv')\n",
    "att1=did2016_200['attraction_id'][did2016_200.treat==1].unique()\n",
    "att2=did2016_100['attraction_id'][did2016_100.treat==1].unique()\n",
    "len(set(att1)-set(att2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T08:05:40.499501Z",
     "start_time": "2019-05-11T08:01:08.330Z"
    }
   },
   "outputs": [],
   "source": [
    "att3=did2016_200['attraction_id'][did2016_200.treat==0].unique()\n",
    "att4=did2016_100['attraction_id'][did2016_100.treat==0].unique()\n",
    "len(set(att4)-set(att3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T08:05:40.500501Z",
     "start_time": "2019-05-11T08:01:08.342Z"
    }
   },
   "outputs": [],
   "source": [
    "treatadd=set(att1)-set(att2)\n",
    "index=[(i in treatadd) for i in did2016_200.attraction_id ]\n",
    "treatadd_data=did2016_200.loc[index,:]\n",
    "treatadd_data[treatadd_data.time==1].describe().to_csv('d:\\\\treatadd_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T08:05:40.502501Z",
     "start_time": "2019-05-11T08:01:08.352Z"
    }
   },
   "outputs": [],
   "source": [
    "controladd=set(att4)-set(att3)\n",
    "index=[(i in controladd) for i in did2016_100.attraction_id ]\n",
    "controladd_data=did2016_100.loc[index,:]\n",
    "controladd_data[controladd_data.time==1].describe().to_csv('d:\\\\controladd_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续型did模型数据（200m、100m等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T09:02:58.725821Z",
     "start_time": "2019-05-12T09:02:52.295454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Adaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2850: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "def continues(year,d):\n",
    "    data=pd.read_csv('%sdid_data_to2016_'%pathdid+str(d)+'m.csv')\n",
    "    data['deal']=data.treat*data.time\n",
    "    data['station_count_'+str(d)].fillna(0,inplace=True)\n",
    "    data['station_counts']=data['station_count_'+str(d)]*data.deal\n",
    "    data.to_csv('%sdid_data_to2016_'%pathdid+str(d)+'m.csv',index=0)\n",
    "continues(2016,100)\n",
    "continues(2016,125)\n",
    "continues(2016,150)\n",
    "continues(2016,175)\n",
    "continues(2016,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 123.18181799999999,
   "position": {
    "height": "40px",
    "left": "513.736px",
    "right": "20px",
    "top": "23.9773px",
    "width": "628px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
